---
title: "Práctica Final en Data Driven Security (Master Cybersecuridad ed.16)"
author: "Grup CC: Toni Jordan y Joan Dalmau"
date: "Junio de 2023"
output:
  html_document:
    toc: yes
    number_sections: yes
    toc_float: true
    toc_collapsed: true
    toc_depth: 4
    df_print: paged
    code_folding: hide
    theme: spacelab
---

```{r setup, results='hide', include=FALSE, message=FALSE, warning=FALSE, cache=TRUE}
# Opciones de configuración de knitr
options(knitr.kable.NA = '')
options(knitr.table.format = "html")
knitr::opts_chunk$set(echo = FALSE, fig.align = 'center')

# Cargar paquetes necesarios
library(readr)
library(caret)        #modelos ML
library(randomForest) #RandomForest
library(nnet)         #Neuronal
library(e1071)        #Naive Bayes
library(dplyr)
library(ggplot2)      #gráficos
library(doParallel)   #paralelizacion
library(corrplot)
library(class)
library(data.table)
library(knitr)
library(kableExtra)
library(foreach)      #paralelizacion
library(grid)
library(DataExplorer)

#Constantes utilizadas en el programa
rf_trees <- 200    #número máximo de arboles para RandomForest Final
limite <- 30       #número mínimo de muestras para considerar el mantener una variable como autónoma
```

# Objetivo

El objetivo de esta práctica es realizar un estudio de un subconjunto del Dataset KDD CUP 99 y determinar el mejor conjunto de variables para utilizar en un modelo de Machine Learning de clasificación.
Para llevar a cabo este estudio, se dispone de dos archivos de datos con incidencias etiquetadas, una codificación de ejemplo en R, información sobre los estándares Mitre de ATT&CK y unas primeras conclusiones sobre los datos.

## Packages
En esta práctica se utilizarán los siguientes paquetes de R:

```{r load_packages, cache=TRUE}
mypackages <- c("randomForest", "nnet", "readr", "caret", "e1071","dplyr","ggplot2", "doParallel","data.table", "kableExtra","corplot","class", "knitr", "tidyr", "grid")

# Crear un data.table con los paquetes
pa<-data.table(mypackages)

# Dividir el data.table en tres partes
colnames(pa)<-c("")

pa <- split(pa, rep(1:4, length.out = nrow(pa)))

kable(pa, caption = " Paquetes a Instalar:",align = c('c'),label = NA) %>%
  kable_styling(bootstrap_options = c("striped", "bordered"),full_width = FALSE) 
```

## Esquema argumental del documento:

El documento se divide en varias secciones:

Análisis y preprocesamiento de los conjuntos de datos: Esta sección carga los conjuntos de datos "Dataset Global" y "Dataset Muestra" y realiza un análisis exploratorio para comprender su estructura y contenido. También se realiza un preprocesamiento de los datos para asegurarse de que sean adecuados para su uso en el entrenamiento con modelos de Machine Learning.

Selector de variables: En esta sección se implementa un selector de variables utilizando el algoritmo de Random Forest. Se comparan diferentes modelos de Machine Learning utilizando diferentes conjuntos de variables y se optimiza el modelo seleccionando el mejor conjunto de variables.

Propuestas de Mejora de la información y de Valor añadido: En esta sección se realizan estudios exploratorios de las variables y se agrega información adicional a los datos utilizando los estándares Mitre ATT&CK y CWE.  

### Validación y pre-porcesado del "Dataset Muestra" respecto al "Dataset Global" entregado  {-}
- Estudio del Dataset Muestra y su contenido  
- Validación de los duplicados en el Dataset Muestra  
- Validación de las proporciones de la variable "Attack" en el Dataset Muestra y posibilidad de aumentar el número de muestras con el Dataset Global  
- Tratamiento de las variables con muy bajas muestras  

### Selector de variables, o Feature Engineering  {-}
- Criterios de selección y prueba de competencia de conjuntos de precursores ante el modelo Random Forest  
- Comparativa de los diferentes modelos Machine Learning de clasificación 
- Optimización del modelo de Machine Learning y conclusiones  

### Mejora de la información y valor añadido  {-}
- Estudios EDA de las variables del DATASET original
- Mejora y Valor Añadido. Información agregada con estándares MITRE ATT&CK y CWE  

# Análisis y preprocesamiento de los conjuntos de datos  

En esta sección, se realizará un análisis exploratorio de los conjuntos de datos "Dataset Global" y "Dataset Muestra". Además, se llevará a cabo un pre procesamiento de los datos para asegurarnos de que sean adecuados para su uso en el entrenamiento de modelos de Machine Learning.  

## Data Loading: carga de los conjuntos de datos  

Comenzamos cargando los conjuntos de datos "Dataset Global"-> Book1.csv (311k muestras) y "Dataset Muestra" -> Book2.csv (77.291 muestras) en R.  

```{r read_dataset, echo=TRUE, cache=TRUE, class.source = 'fold-show'}
data_full <- read_csv("Book1.csv",
                  col_types = cols(SrcBytes = col_integer(),
                                   DstBytes = col_integer(), Land = col_integer(),
                                   WrongFragment = col_integer(), Urgent = col_number(),
                                   Hot = col_number(), NumFailedLogin = col_integer()))
data <- read.csv("Book2.csv", header=T)
```

### Data Exploration: exploración de los conjuntos de datos  

El Análisis Exploratorio de Datos (EDA, por sus siglas en inglés) es la fase inicial y importante del análisis de datos/modelado predictivo. Durante este proceso, se da un primer vistazo a los datos y se generar hipótesis relevantes y decidirán los siguientes pasos. 

A continuación, realizaremos un análisis exploratorio de los conjuntos de datos entregados en la práctica para comprender su estructura y contenido, La primera tabla corresponde a las primeras filas del Dataset Global y la segunda del Dataset Muestra:

```{r explore_data, cache=TRUE}
# Visualizar las primeras filas del Dataset Global
head(data_full)

# Visualizar las primeras filas del Dataset Muestra
head(data)
```

El conjunto de datos "Dataset Muestra" contiene las mismas columnas que el conjunto de datos "Dataset Global" y cada fila representa un incidente y tampoco contiene muestras vacías, luego se podrá utilizarar para nuestro estudio.  

```{r study_sample_data_1, echo=TRUE, eval=FALSE, results='hide', class.source = 'fold-show'}
# Resumen del conjunto de datos de muestra
summary(data)

# Tipos de datos de las columnas del conjunto de datos de muestra
str(data)
dim(data)
```

```{r study_sample_data_1b, results='hide', cache=TRUE}
# Obtener los tipos de datos de las columnas del dataset
tipos_datos <- sapply(data, class)
# Crear una tabla con los tipos de datos
tabla_tipos_datos <- data.frame(Columna = names(data), Tipo = tipos_datos)
```
El conjunto de Datos Muestra tiene **`r nrow(data)`** filas y **`r ncol(data)`** columnas. Se distribuyen en los siguientes tipos:  
```{r study_sample_data_2, eval=TRUE, echo=TRUE, fig.align='center', class.source = 'fold-show'}
# Imprimir la tabla resumen usando la función kable()
kable(tabla_tipos_datos, caption = "tipos de Variables") %>%
    kable_styling(bootstrap_options = c("striped"), full_width = F)

DataExplorer::plot_str(data)
```

### Data Preprocessing: validación y preprocesamiento del conjunto de datos de muestra  

En esta sección, se realizarán algunas validaciones y preprocesamientos en el conjunto de datos Muestra para asegurarnos de que cumpla con nuestros requisitos.  

#### Estudio del conjunto de datos de muestra y su contenido  

A continuación, se realizará un estudio más detallado del conjunto de datos Muestra y su contenido.  

```{r study_data_1, cache=TRUE}
# Contar el número de variables cualitativas, cuantitativas y factor
num_qualitative <- sum(sapply(data, is.character))
num_quantitative <- sum(sapply(data, is.numeric))
num_factor <- sum(sapply(data, is.factor))

# Crear una tabla resumen
summary_table <- data.frame(Tipo = c("Cualitativa", "Cuantitativa", "Factor"),
                            Numero = c(num_qualitative, num_quantitative, num_factor))
  
# Imprimir la tabla resumen usando la función knitr::kable()
kable(summary_table, caption = "Clasificación por tipos de Variables") %>%
    kable_styling(bootstrap_options = c("striped"), full_width = F)
```

- El Dataset contiene **`r summary_table$Numero[2]`** variable numéricas cuantitativas y **`r summary_table$Numero[1]`** variables cualitativas.    
```{r study_data_2, results='hide', cache=TRUE}
# Obtener solo las variables cualitativas y los valores de estas
qualitative_vars <- select_if(data, is.character)
distinct_values <- lapply(qualitative_vars, unique)

# Crear una tabla resumen
summary_table2 <- data.frame(Variable = character(), Valores = character(), Categorias = integer(), stringsAsFactors = FALSE)

# Llenar la tabla resumen con los valores diferentes y el número de categorías de cada variable cualitativa
llista <- ""
for (i in 1:length(distinct_values)) {
  variable <- names(distinct_values[i])
  values <- paste(distinct_values[[i]], collapse = ", ")
  num_categories <- length(distinct_values[[i]])
  llista<- as.character(paste(llista,variable,","))
  summary_table2 <- rbind(summary_table2, data.frame(Variable = variable, Categorias = num_categories, Valores = values))
}
### Ordenar la tabla resumen por nombre de variable
summary_table2 <- summary_table2 %>% arrange(Variable)
```

- Las columnas con variables cualitativas son: `r llista` que contendrá la variable usada como Factor.  

```{r study_data_3, cache=TRUE}
# Imprimir la tabla resumen
kable(summary_table2, caption = "Clasificación por Variables cualitativa") %>%
    kable_styling(bootstrap_options = c("striped", "condensed"))
```
```{r study_data_4, results='hide', fig.align='center', fig.cap='Variables Cualitativas', cache=TRUE}
# Crear un gráfico explicativo por cada variable cualitativa
num_variables <- nrow(summary_table2)
num_rows <- 2  # Número de filas en la matriz de gráficos
num_cols <- ceiling(num_variables / num_rows)  # Número de columnas en la matriz de gráficos

# Establecer la disposición de los gráficos
layout(matrix(1:num_variables, nrow = num_rows, ncol = num_cols))

for (i in 1:num_variables) {
  variable <- summary_table2$Variable[i]
  plot_data <- table(data[[variable]])
  plot <- barplot(plot_data, main = paste("Muestras de ", variable),
                  xlab = "Valor Cualitativo", ylab = "Número de Muestras",
                  col = "skyblue", border = "white")
  print(plot)
}

# Restaurar la configuración del dispositivo gráfico
layout(1)
```

### Feature Engineering 

#### Validación de duplicados en el conjunto de datos de muestra

Vamos a validar si el conjunto de datos de la muestra contiene filas duplicadas y, en caso afirmativo, eliminaremos las filas duplicadas.
```{r dup_study_data_1, echo=TRUE, cache=TRUE, class.source = 'fold-show', message=FALSE}
# Calcular el número de muestras duplicadas o iguales en el Dataset
duplicates <- data %>%
  group_by_all() %>%
  filter(n() > 1) %>%
  summarise(Num_Duplicates = n()) %>%
  arrange(desc(Num_Duplicates))
```

```{r dup_study_data_2, cache=TRUE}
# Imprimir la tabla ordenada
cat("Número de muestras duplicadas en Dataset:", nrow(duplicates), "\n")
# Eliminar las muestras duplicadas y conservar solo una muestra de ellas
kdd_data_unique <- distinct(data, .keep_all = TRUE)
# Calcular el número de muestras duplicadas eliminadas
duplicates <- nrow(data) - nrow(kdd_data_unique)
# Imprimir el número de muestras duplicadas eliminadas
cat("Número de muestras duplicadas eliminadas:", duplicates, "\n")
rm(kdd_data_unique) #eliminamos dataset temporal
```
> **Se confirma que el DATASET de trabajo es correcto y no tiene muestras duplicadas.**  

```{r per_study_data_1, cache=TRUE}
# Constantes: valor extremo de la diferencia de porcetage permitido XX% y cantidad mínima de muestras
difer_n <- 3
cant_min <- 1000
```
#### Con el siguiente estudio se pretende analizar y comparar el **Dataset Muestra** y el **Dataset Global**  

El objetivo aquí seria validar si podemos añadir mas muestras del **Dataset Global** para mejorar el **Dataset Muestra**, para ello se observa si hay muestras diferentes que podamos extraer de aquellos tipos de ataque con un número inferior a **`r cant_min `** muestras en el Dataset de trabajo.  

Para ello, eliminamos filas duplicadas dejando solo filas únicas en el **Dataset Global** y comparamos los dos juegos de datos:  
```{r per_study_data_2, echo=TRUE, cache=TRUE, class.source = 'fold-show'}
# Eliminar las muestras duplicadas y conservar solo una muestra de ellas
kdd_data_full_unique <- distinct(data_full, .keep_all = TRUE)
```
```{r per_study_data_3, cache=TRUE}
# Calcular el número de muestras duplicadas eliminadas
duplicates <- nrow(data_full) - nrow(kdd_data_full_unique)
```
```{r per_study_data_4, echo=TRUE, cache=TRUE}
data_full <- kdd_data_full_unique
```
```{r per_study_data_5, cache=TRUE, fig.align='center'}
rm(kdd_data_full_unique) #eliminamos el dataset temporal
# Imprimir el número de muestras duplicadas eliminadas
cat("Número de muestras duplicadas eliminadas en Dataset Full:", duplicates, "\n")

# Calcular la frecuencia y porcentaje de casos por valor de Attack
attack_counts_full <- data_full[data_full$Attack != "normal.", ] %>% 
  count(Attack) %>%
  mutate(Percentage_Full = round(n/sum(n) * 100, 2)) %>%
  arrange(desc(Percentage_Full))

attack_counts <- data[data$Attack != "normal.", ] %>% 
  count(Attack) %>%
  mutate(Percentage = round(n/sum(n) * 100, 2)) %>%
  arrange(desc(Percentage))

# Crear una tabla combinada con los totales y porcentajes
attack_table <- merge(attack_counts_full, attack_counts, by = "Attack", suffixes = c("_Full", "_Muestra"))
attack_table <- attack_table[order(attack_table$n_Full, decreasing = TRUE),]

# Calcular la diferencia entre Diponible_Full y Disponible_Muestra
attack_table$Disponibles <- attack_table$n_Full-attack_table$n_Muestra

# Filtrar los casos con diferencia mayor al XX%
filtered_attack_table_n <- attack_table[attack_table$Disponibles > 0, ]

# Imprimir la tabla comparativa
kable(attack_table, caption = "Comparativa número de attaques por cada Dataset") %>%
    kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F)

# Imprimir la tabla de casos con diferencia mayor al XX%
cat("Número de muestras disponibles diferentes en el Dataset Full:", nrow(filtered_attack_table_n), "\n")

# Crear un gráfico de barras comparativo
ggplot(attack_table, aes(x = Attack)) +
  geom_bar(aes(y = n_Full, fill = "Data_Full"), stat = "identity", just = 0) +
  geom_bar(aes(y = n_Muestra, fill = "Data"), stat = "identity", just = 1) +
  labs(title = "Número de casos por valor de Attack", x = "Attack", y = "Muestras") +
  scale_fill_manual(values = c("blue", "red"), guide = guide_legend(title = "Dataset")) +
  ggtitle("Diferencia de Muestras en Data_Full vs Data") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

>Con el anterior estudio se concluye que no es posible poblar con nuevas muestras el **Dataset Muestra** ya que en el Dataset Global tiene todas las muestras adicionales duplicadas respecto a las disponibles en el dataset de trabajo. Para conseguir nuevas se debería probar a descargar nuevas muestras desde el repositorio:   
>
>- Source data [KDD Cup 1999 Data Data Set](https://archive.ics.uci.edu/ml/datasets/kdd+cup+1999+data), _pero se aparcará para abordarlo en una prática con mas tiempo de entrega_  
>
>- **Finalmente se elimina el 'DataSet Global' y se mantiene el Dataset Muestra original**.  

```{r per_study_data_6, cache=TRUE, echo=TRUE, class.source = 'fold-show'} 
rm(data_full) #eliminamos data_full, ya no es útil
```

### Selección y mejoras en el **Dataset Muestra**  

La teoría nos dice que, aunque la creación de un buen modelo debe entenderse como un proceso iterativo, en el que se van ajustando y probando distintos modelos, existen ciertas pistas que pueden ayudar a realizar una selección inicial adecuada.

Si dos variables numéricas están muy Correlacionadas, añaden información redundante al modelo, por lo tanto, no conviene incorporar ambas. Si esto ocurre, se puede: excluir aquella que, acorde al criterio del analista, no está realmente asociada con la variable respuesta; o combinarlas para recoger toda su información en una única nueva variable, por ejemplo, con un PCA.

Si una variable tiene varianza igual o próxima a cero (su valor es el mismo o casi el mismo para todas las observaciones) añade al modelo más ruido que información, por lo que suele ser conveniente excluirla.

Si alguno de los niveles de una variable cualitativa tiene muy pocas observaciones en comparación a los otros niveles, puede ocurrir que, durante la validación cruzada o bootstrapping, algunas particiones no contengan ninguna observación de dicha clase (Varianza cero), lo que puede dar lugar a errores. En estos casos, suele ser conveniente eliminar las observaciones del grupo minoritario (si es una variable multiclase), eliminar la variable (si solo tiene dos niveles) o asegurar que, en la creación de las particiones, se garantice que todos los grupos estén representados en cada una de ellas.

#### Tratamiento de las muestras residuales  

Procedemos a buscar los casos 'Attack' etiquetados con bajo número de muestras, menos de:  **`r limite`** y agruparlos en una nueva etiqueta 'other'  

```{r res_study_data_1, results='hide', fig.align='center', out.width='50%', fig.show='hold', fig.cap='Agrupando muestras', cache=TRUE}
# Crear un gráfico de barras del porcentaje de casos por valor de Attack sin agrupar
ggplot(attack_counts, aes(x = reorder(Attack, -Percentage), y = Percentage)) +
  geom_bar(stat = "identity", fill = "blue") +
  labs(title = "Porcentaje de casos por valor de Attack (original)",
       x = "Attack",
       y = "Porcentaje de casos") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Reemplazar valores inferiores a XX por "other" en el dataset data
data$Attack <- ifelse(data$Attack %in% attack_table$Attack[attack_table$n_Muestra < limite], "other", data$Attack)

# Filtrar los casos que no tienen el valor "normal."
data_filtered <- data %>% filter(Attack != "normal.")

# Contar la frecuencia de los valores en la columna "Attack"
frecuencia_attack <- sort(table(data_filtered$Attack), decreasing = TRUE)

# Calcular el porcentaje de casos por valor de Attack
attack_counts <- data_filtered %>% 
  count(Attack) %>%
  mutate(Percentage = round(n/sum(n) * 100, 2)) %>%
  arrange(desc(Percentage))

# Crea una tabla ordenada con los totales
attack_table_final <- data.frame(
  Attack = names(frecuencia_attack), 
  Total = as.numeric(frecuencia_attack), 
  Porcentaje = as.numeric(attack_counts$Percentage)
)
attack_table_final <- attack_table_final[order(attack_table_final$Total, decreasing = TRUE), ]

# Crear un gráfico de barras del porcentaje de casos por valor de Attack una vez agrupado
ggplot(attack_counts, aes(x = reorder(Attack, -Percentage), y = Percentage)) +
  geom_bar(stat = "identity", fill = "blue") +
  labs(title = "Porcentaje de casos por valor de Attack (agrupado)",
       x = "Attack",
       y = "Porcentaje de casos") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
```{r res_study_data_2, cache=TRUE}
# Imprimir la tabla comparativa
kable(attack_table_final, caption = "Comparativa número de attaques del nuevo Dataset Muestra") %>%
    kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F)
```

#### Selección de Predictores, (PCA), para una primera iteración

Sección de generación de las diferentes Colecciones de variables en conjuntos preseleccionado de variables.

#### Colección 1 por criterio Enunciado, en el enunciado de la práctica se han seleccionado las siguientes variables:  {-}
- **SrcBytes**: Representa la cantidad de bytes de datos enviados desde la fuente al destino.
- **DstBytes**: Representa la cantidad de bytes de datos enviados desde el destino a la fuente.
- **Land**: Indica si la conexión es de/a la misma máquina/puerto.
- **WrongFragment**: Representa el número de fragmentos "incorrectos".
- **Urgent**: Indica el número de paquetes urgentes.
- **SameSrvRate**: Representa el porcentaje de conexiones al mismo servicio.
- **LoggedIn**: Indica si el usuario ha iniciado sesión o no.
- **DstHostSameSrvRate**: Representa el porcentaje de conexiones al mismo servicio que la conexión actual en los últimos dos segundos.
- **DstHostSrvCount**: Representa el número de conexiones al mismo servicio que la conexión actual en los últimos dos segundos.
- **Flag**: Representa el estado de la conexión.
- **Attack**: Representa la variable objetivo, indicando si la conexión es un ataque o no.

#### Colección 2 por criterio PDF ejemplo, conjuntamente con el enunciado se aporta un ejemplo en PDF de un anterior alumno donde se escogieron este otro conjunto de variables, aunque no conocemos su justificación:  {-}
- **SrcBytes**: Representa la cantidad de bytes de datos enviados desde la fuente al destino.
- **DstBytes**: Representa la cantidad de bytes de datos enviados desde el destino a la fuente.
- **DstHostSameSrvRate**: Representa el porcentaje de conexiones al mismo servicio que la conexión actual en los últimos dos segundos.
- **Count**: Esta variable cuenta la frecuencia de conexiones que se han realizado al mismo host durante un período de tiempo determinado.
- **DstHostDiffSrvRate**: Representa el porcentaje de conexiones que tienen diferentes servicios en el mismo host destino en los últimos dos segundos.
- **Attack**: Representa la variable objetivo, indicando si la conexión es un ataque o no.

#### Colección 3 por criterio Teórico, por algunas combinaciones de variables que podrían ser consideradas en el contexto de una práctica académica, (según fuente Google + ChatGPT 3):  {-}
- **Protocol_type + Service + Flag**: Esta combinación de variables puede ser útil para capturar patrones específicos de ataques según el tipo de protocolo, el servicio de red y el estado de la conexión. Por ejemplo, ciertos tipos de ataques pueden estar asociados con protocolos específicos o servicios particulares.
- **Duration + Src_bytes + Dst_bytes**: Estas variables pueden proporcionar información sobre la duración de la conexión y la cantidad de bytes transferidos tanto desde el origen como hacia el destino. La combinación de estas variables puede ayudar a identificar ataques de denegación de servicio o ataques que involucren una transferencia de datos inusualmente grande.
- **Protocol_type + Service + Flag + Src_bytes + Dst_bytes**: Al combinar las variables anteriores con las variables adicionales relacionadas con el tipo de protocolo, el servicio y el estado de la conexión, se puede obtener una visión más completa de las características de las conexiones y aumentar la capacidad de detección de ataques específicos.

```{r feature_selection_1, cache=TRUE}
# Enunciado de la práctica
data1_original <- data[,c("SrcBytes", "DstBytes", "Land", "WrongFragment", "Urgent", "SameSrvRate", "LoggedIn",  "DstHostSameSrvRate", "DstHostSrvCount","Flag","Attack" )]
data1_original$Attack <- as.factor(data1_original$Attack)
# PDF de soporte
data1_pdf <- data[,c("SrcBytes", "DstBytes", "DstHostSameSrvRate", "Count", "DstHostDiffSrvRate","Attack" )]
data1_pdf$Attack <- as.factor(data1_pdf$Attack)
# Criterio teórico de los expertos en Networking
data1_teorico <- data[,c("SrcBytes", "DstBytes", "Duration", "ProtocolType", "Service", "Flag", "Attack" )]
data1_teorico$Attack <- as.factor(data1_teorico$Attack)
```

#### Colección 4 por criterio matemático, usando una combinación de selección de las variables finales por criterios puramente estadísticos:  {-}
Este criterio se basará en la eliminación de columnas sobrantes según dos rozamientos estadísticos:  
- variables con una **Varianza cero** o muy cercana al cero  
- variables con un alto índice de **Correlación** entre ellas (>0.90).  
```{r feature_selection_2, cache=TRUE}
# 1. Criterio de la Varianza nula o cerca del cero, columnas que se eliminan:
# "SrcBytes", "DstBytes", "Count", "DstHostSameSrvRate", "DstHostDiffSrvRate", "DstHostSrvDiffHostRate", "LoggedIn","SrvCount", 
# "SerrorRate", "SrvSerrorRate", "RerrorRate", "SrvRerrorRate", "DiffSrvRate","SrvDiffHostRate", "DstHostSrvCount", 
# "DstHostSameSrcPortRate", "DstHostSerrorRate", "DstHostSrvSerrorRate", "DstHostRerrorRate", "DstHostSrvRerrorRate", "NumOutboundCmds" 

# me quedo solo con las variables numéricas en nuevo data1 para calcular varianzas
numeric_cols <- sapply(data, is.numeric)
data1 <- data[, numeric_cols == TRUE] 
# elimino variables con Varianza zero "NumOutboundCmds" y nzv 
variance <- nearZeroVar(data1, saveMetrics = T)
data1 <- data1[, !(variance$zeroVar | variance$nzv)]
# Filtrar los valores de zeroVar y nzv
variance_filtered <- variance[variance$zeroVar | variance$nzv, ]

# Imprimir la tabla resumen
kable(variance_filtered, caption = "Variables a eliminar por su baja Varianza") %>%
    kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F)

# Buscamos variables correladas para eliminarlas
correlation <- cor(data1)
highlyCorrelated <- findCorrelation(correlation, verbose=F, names=T)  #selecciona a partir del 0.9 de indice de correlación

# Convertir highlyCorrelated en una única fila
highlyCorrelated_row <- paste("Correlación:", paste(highlyCorrelated, collapse = ", "))

corrplot(correlation, method="circle", title="Variables con alta Correlación", na.label= '.')

# Eliminamos filas 
data1 <- data1[, setdiff(names(data1), highlyCorrelated)]

# Añadir la variable factor "Attack" al dataset filtrado
data1$Attack <- as.factor(data$Attack)
```

- Estas son las variables a eliminar por su alta **`r highlyCorrelated_row`** que son eliminadas del Dataset  

>Se toman los cuatro juegos de variables para generar cuatro nuevos **Dataset Muestra** y resultan con los siguientes tamaños:  
>
>- 1. Dataset Enunciado: **`r ncol(data1_original)`** variables  
>- 2. Dataset Ejemplo PDF: **`r ncol(data1_pdf)`** variables  
>- 3. Dataset Teórico: **`r ncol(data1_teorico)`** variables  
>- 4. Dataset Estadístico: **`r ncol(data1)`** variables  

Procedemos a enfrentar los cuatro conjuntos de Dataset Muestra contra el modelo de entrenamiento **RandomForest**, tomando solo un 10% de las muestras para agilizar los cálculos y comparamos resultados de **Accuracy**  

```{r feature_selection_3, results='hide', cache=TRUE}
divide <- 0.1  # 10%, toma mínima de muestras para acelerar el cálculo

set.seed(123)

# Crear partición de entrenamiento y prueba para cada Dataset
datasets <- list(
#  Estadistico = data1,
  Enunciado = data1_original,
  Ejemplo_pdf = data1_pdf,
  Teorico_net = data1_teorico,
  Estadistico = data1
)

particion <- lapply(datasets, function(data) {
  inTrain <- createDataPartition(y = data$Attack, p = divide, list = FALSE)
  list(training = data[inTrain,], testing = data[-inTrain,])
})

# Función para ajustar un modelo de random forest y obtener las predicciones
ajustar_rf <- function(data) {
  start_time <- Sys.time()
  model <- randomForest(Attack ~ ., data = data$training, ntree = rf_trees, na.action = na.fail)
  end_time <- Sys.time()
  elapsed_time <- round((end_time - start_time), 2)
  pred <- predict(model, data$testing)
  cm <- confusionMatrix(pred, data$testing$Attack)
  accuracy <- round(cm$overall[1], 4) * 100
  kappa <- round(cm$overall[2], 4) * 100
  list(model = model, pred = pred, accuracy = accuracy, kappa = kappa, cm = cm, tiempo = elapsed_time)
}

# Ajustar modelos y obtener resultados para cada dataset
resultados <- lapply(particion, ajustar_rf)

# Crear tabla de resultados
tabla_resultados <- data.frame(
  Variable = names(resultados),
  Accuracy = sapply(resultados, function(res) res$accuracy),
  Kappa = sapply(resultados, function(res) res$kappa),
  Tiempo = sapply(resultados, function(res) res$tiempo)
)
```
```{r feature_selection_4, cache=TRUE}
# Imprimir la tabla de resultados
kable(tabla_resultados, caption = "Comparativa por juego de predictores") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)
```
```{r feature_selection_5, cache=TRUE, fig.align='center', fig.cap='validando variables', out.width='50%', fig.show='hold', results='hide'}
# Función para generar el gráfico y mapa de calor para cada modelo
generar_grafico <- function(result, cm, caption) {
  plot(result$model, main= caption)
  heatmap(cm$table)
  title(caption)
}

# Generar gráficos y mapas de calor para cada modelo
lapply(seq_along(resultados), function(i) generar_grafico(resultados[[i]], resultados[[i]]$cm, tabla_resultados$Variable[i]))
# Eliminar datasets y objetos temporales
rm(datasets, particion, resultados)
```

> **Conclusión:** una vez batido el porcentaje de aciertos de la colección facilitada en el enunciado, nos podemos quedar con la propuesta del Dataset con variables escogidas por criterios puramente estadísticos y en los siguientes pasos veremos como seria posible mejorar y superar también el resultado obtenido por el ejemplo entregado con la práctica.

### Data Visualization:  
enfrentamos ahora el juego de variables escogido, **'Dataset Muestra Estadístico'**, con varios modelos de entrenamiento (ML), para comprobar esta vez cual seria mas óptimo para este Dataset concreto.   

```{r other_model_tests_1, results='hide', fig.align='center', out.width='50%', fig.show='hold', fig.cap='validando modelos', cache=TRUE}
divide <- 0.1  # 10%, toma mínima de muestras para acelerar el cálculo

set.seed(123)
inTrain <- createDataPartition(y=data1$Attack, p=divide, list=FALSE)
training <- data1[inTrain,]
testing <- data1[-inTrain,]

# Función para calcular precisión y tiempo de ejecución
calculate_accuracy_time <- function(model, training, testing, method_name) {
  end_time <- Sys.time()
  elapsed_time <- round((end_time - start_time), 2)
  pred <- predict(model, testing)
  cm_model <- confusionMatrix(pred, testing$Attack)
  cm_accuracy <- round(cm_model$overall[1], 4)*100
  cm_kappa <- round(cm_model$overall[2], 4)*100
  heatmap(cm_model$table)
  title(method_name)
  list(Modelo = method_name, Accuracy = cm_accuracy, Kappa = cm_kappa, Tiempo = elapsed_time)
}
results <- list()

# Random Forest
start_time <- Sys.time()
rf_model <- randomForest(Attack ~ ., data = training, ntree = 100)  ##100 mínimo
plot(rf_model, main="Random Forest")
results$rf <- calculate_accuracy_time(rf_model, training, testing, "Random Forest")

# Support Vector Machine
start_time <- Sys.time()
svm_model <- svm(Attack ~ ., data = training)
results$svm <- calculate_accuracy_time(svm_model, training, testing, "Support Vector Machine")

# CART (Classification and Regression Trees)
control <- trainControl(method = "cv", number = 2)
start_time <- Sys.time()
fit.cart <- train(Attack ~ ., data = training, method = "rpart", metric = "Accuracy", trControl = control)
results$cart <- calculate_accuracy_time(fit.cart, training, testing, "CART")

# KNN (K-Nearest Neighbors), me quedo con las variables numéricas
num_vars = sapply(training, is.numeric)
training_num = training[, num_vars]
num_vars = sapply(testing, is.numeric)
testing_num = testing[, num_vars]

start_time <- Sys.time()
knn_model <- knn(train = training_num, test = testing[, 1:12], cl = training$Attack, k = 5)
end_time <- Sys.time()
elapsed_time <- round((end_time - start_time), 2)
cm_model <- confusionMatrix(knn_model, testing$Attack)
heatmap(cm_model$table)
title("K-Nearest Neighbors")
results$knn <- list(Modelo = "K-Nearest Neighbors",
                    Accuracy = round(cm_model$overall[1], 4) * 100,
                    Kappa = round(cm_model$overall[2], 4) * 100,
                    Tiempo = elapsed_time)

# Naive Bayes
start_time <- Sys.time()
nb_model <- naiveBayes(Attack ~ ., data = training)
results$nb <- calculate_accuracy_time(nb_model, training, testing, "Naive Bayes")
```
```{r other_model_tests_2, cache=TRUE}
# Resultados
results_t <- data.frame(Modelo = c(results$rf$Modelo, results$svm$Modelo, results$cart$Modelo,
                                    results$knn$Modelo, results$nb$Modelo),
                      Accuracy = c(results$rf$Accuracy, results$svm$Accuracy, results$cart$Accuracy,
                                    results$knn$Accuracy, results$nb$Accuracy),
                      Kappa = c(results$rf$Kappa, results$svm$Kappa, results$cart$Kappa,
                                    results$knn$Kappa, results$nb$Kappa),
                      Tiempo = c(results$rf$Tiempo, results$svm$Tiempo, results$cart$Tiempo,
                                    results$knn$Tiempo, results$nb$Tiempo))

kable(results_t, caption = "Resultados por métodos de Clasificación") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)
```

> Como resultado de la comparativa sigue dando mejor resultado el método de **Random Forest**

### Machine Learning and Intrusion Detection:   
Una vez decidido el entrenamiento con Random Forest y el **'Dataset Muestra Estadístico'**, pasamos a intentar mejorar el ratio de aciertos ajustando algunos parámetros del modelo, para ello incrementamos a un **50%** de las muestras para el entrenamiento, ya que se ha visto que tomar mas de este porcentaje no incrementa significativamente el ratio de acierto y empeora mucho el tiempo de cálculo.  
Posteriormente, intentaremos mejorarlo añadiendo también alguna nueva variables como será la columna: **'SrcBytes'** y con ello intentar batir el resultado obtenido con el ejemplo facilitado.  

```{r tunning_RF_model_tests_1, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
rf_trees_fin <- rf_trees #200
part_fin <- 0.5 
set.seed(123)

# Añadir columna "Anomaly" al dataset data1, eliminado ya que desvirtua el modelo de entrenamiento.
#data1$Anomaly <- ifelse(data1$Attack == "normal.", FALSE, TRUE)
#data1$Anomaly <- as.factor(data1$Anomaly)
# Se añade la variable numerica SrcBytes ya que ha detectado que mejora la predicción
data1$SrcBytes <- data$SrcBytes

data1$Attack <- as.factor(data1$Attack)

# Prepara la división entre training y testing
inTrain_fin <- createDataPartition(y=data1$Attack, p=part_fin, list=FALSE)
training_fin <- data1[inTrain_fin,]
testing_fin <- data1[-inTrain_fin,]

# Entrenar el modelo de Random Forest
control <- rfeControl(functions=rfFuncs, method="cv", number=10)

start_time <- Sys.time()
rf_fin_model <- randomForest(Attack ~ ., 
                          data = training_fin,
                          mtry = 5,
                          rfeControl=control,
                          ntree = rf_trees_fin)
end_time <- Sys.time()
elapsed_time_fin <- round((end_time - start_time), 2)
rf_fin_pred <- predict(rf_fin_model, testing_fin)

cm_fin <- confusionMatrix(rf_fin_pred, testing_fin$Attack)

#predictors(rf_fin_model) variables
plot(rf_fin_model)
heatmap(cm_fin$table)

resultado_final <- data.frame( Accuracy= as.numeric(round(cm_fin$overall[1], 4)*100),
                               Kappa= as.numeric(round(cm_fin$overall[2], 4)*100),
                               Tiempo= as.numeric(elapsed_time_fin))

kable(resultado_final, caption = "Resultado para Clasificación por RandomForest") %>%
    kable_styling(bootstrap_options = c("striped"), full_width = F)
```

> Finalmente, se obtiene una precisión del **`r resultado_final$Accuracy`** equilibrando el número de variables, las muestras entrenadas y el valor de árboles que máximiza el resultado optimizando el tiempo de cálculo.

### Model Evaluation: 
Se ejecuta ahora el cálculo de las métricas finales y se crea tabla resumen con la precisión obtenida por cada tipo de **'Attack'**:  

```{r tunning_RF_model_tests_2, echo=TRUE, cache=TRUE, fig.align='center'}
# Crear una nueva columna "match" en la tabla valid
valid <- testing_fin %>%
  mutate(Attack = as.character(Attack),
         pred = as.character(rf_fin_pred),
         match = Attack == pred)

# Calcular el número total de registros por variable Attack
total_per_attack <- table(valid$Attack)

# Calcular el número de aciertos por variable Attack
aciertos_per_attack <- tapply(valid$match, valid$Attack, function(x) sum(x))

# Calcular el número de fallos por variable Attack
fallos_per_attack <- total_per_attack - aciertos_per_attack

# Calcular el Accuracy por variable Attack
accuracy_per_attack <- round((aciertos_per_attack / total_per_attack *100), 2)

# Crear la tabla tabla_fin con fallos, aciertos y Accuracy por variable Attack
tabla_fin <- data.frame(Attack = names(total_per_attack),
                        Aciertos = as.integer(aciertos_per_attack),
                        Fallos = as.integer(fallos_per_attack),
                        Accuracy = as.numeric(accuracy_per_attack))

# Ordenar la tabla_fin por Accuracy y Total Aciertos
tabla_fin <- tabla_fin %>%
  arrange(desc(Accuracy), desc(Aciertos))

# Mostrar la tabla tabla_fin actualizada
kable(tabla_fin, caption = "Resultado por tipo de Attack") %>%
    kable_styling(bootstrap_options = c("striped"), full_width = F)

# Mostrar el gráfico
ggplot(tabla_fin, aes(x = reorder(Attack, -Accuracy), y = Accuracy)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Relación de aciertos por tipo de Attack",
       x = "Tipo de Attack",
       y = "Grado de Acierto")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

> Finalmente se observa que en la mayoria de casos de **'Attack'** se conseguirá un ratio de acierto por encima del _90%_, a excepción de los últimos 3 casos pero que por otro lado, son muy minoritarios en número de muestras, por lo que debería obtenerse muchas más muestras de estos casos en particular y explorarse nuevas combinaciones de variables en un proceso de mejor iterada. 

# Mejora del EDA: 

Esta sección serviría para completar el estudio de los datos y sus relaciones, con el objetivo de seguir iterando en encontrar nuevos conjuntos de variables que perfeccionen el modelo de entrenamiento y se consiga un mejor ratio de aciertos

_Nota: por falta de tiempo se anotaran solo algunos trabajos exploratorios realizados hasta el momento de la entrega con objeto de abordarlos en un futuro_

## Teniendo en cuenta las Categorias principales de intrusiones:   

-**DoS:** ataque de denegación de servicio, e.g.'syn flood'  
-**R2L:** ataque de acceso remoto, e.g. 'guessing password'  
-**U2R:** ataque de escalado a privilegios de Usuario local (root), e.g., `buffer overflow'  
-**probing:** ataque de sondeo, e.g., 'port scanning'  

## Teniendo en cuenta las variables cualitativas y su significado:   
- **Protocol_type:** El tipo de protocolo utilizado en una conexión puede ayudar a distinguir entre diferentes tipos de ataques. Por ejemplo, ciertos tipos de ataques pueden estar más asociados con protocolos específicos.
- **Service:** El servicio de red al que se accede en una conexión puede proporcionar información sobre la naturaleza de la actividad. Algunos servicios pueden ser más susceptibles a ciertos tipos de ataques.
- **Flag:** El estado de la conexión puede indicar comportamientos anómalos, como conexiones establecidas inusualmente largas o múltiples intentos de restablecimiento de conexiones.
- **Duración:** La duración de una conexión puede ser un indicador de ataques prolongados o sesiones anómalas que podrían requerir una mayor atención.
- **Bytes transferidos:** La cantidad de bytes transferidos en una conexión puede ayudar a identificar ataques de inundación o de denegación de servicio, donde hay un flujo inusualmente alto de datos.

## Teniendo en cuenta las relación posible entre las variables y las categorias de intrusión:   

Observación: **'DstHostSameSrcPortRate'** tiene un ligero efecto en el tipo de intrusión, para "DstHostSameSrcPortRate" mayor a igual a 1 puede ser un "probe" de "R2L"  
```{r eda_1, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
qplot(DstHostSameSrvRate,DstHostSrvCount,colour=Attack,data=data)
```

Gráfica de la **media** de la duración del ataque y su **mediana**  
```{r eda_2, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
ggplot(data=data, aes(x=data$Attack, y=Duration, fill = Attack)) + 
  geom_bar(stat = "summary", fun.y = "mean")+scale_x_discrete(name = "Attack")+
  scale_y_continuous("Duration")+labs(title="Mean attack duration", fill=("Attack\n") )

#median attack duraction
ggplot(data=data, aes(x=Attack, y=Duration, fill = Attack)) + 
  geom_bar(stat = "summary", fun.y = "median")+scale_x_discrete(name = "Attack")+
  scale_y_continuous("Duration")+labs(title="Median attack duration", fill=("Attack\n") )
```

Los gráficos muestran que las duraciones promedio reflejan el tipo de ataque. De hecho, un ataque de denegación de servicio (DoS) tiene una duración promedio de cero, ya que su objetivo es dejar inutilizable un dispositivo físico en la red. De esta manera, el servicio se interrumpe y la duración promedio es casi cero.  
Es importante tener en cuenta que un ataque de sondeo (probe), que busca obtener la mayor cantidad de información posible sobre la seguridad de la red, tiene una duración promedio más larga.  
Por otro lado, solo el ataque de Usuario a Raíz (U2R) tiene una mediana muy alta. De hecho, las duraciones de este ataque son comparables entre sí, mientras que esto no sucede en otros tipos de ataques que tienen duraciones muy variables entre ellos.  

- Gráfica de la media de la duración del ataque basado en el **tipo de protocolo.**   
```{r eda_3, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
ggplot(data=data, aes(x=Attack, y=Duration, fill = ProtocolType)) + 
  geom_bar(stat = "summary", fun.y = "mean")+scale_x_discrete(name = "Attack")+
  scale_y_continuous("Duration")+ scale_fill_discrete(name = "Protocol type\n")+
  labs(title="Average duration of attacks based on the type of protocol" )
```

Como se puede observar en el gráfico, los tipos de ataques reflejan la duración promedio basada en el tipo de protocolo. De hecho, muchos ataques utilizan el protocolo TCP que se utiliza ampliamente para implementar diferentes servicios. El uso extensivo del protocolo UDP en casos normales es extraño, pero depende del tipo de solicitudes de servicio del usuario.

-Observaciones individuales usando **Duration**, **Attack** y **ProtocolType**.  
```{r  eda_4, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
p1 <- ggplot(data,aes(y = Duration, x = Attack)) +
  geom_point()
p1 +  geom_point(aes(color=ProtocolType))+
  labs(title="Duration, attack and protocol type" , color ="Protocol type")+
  scale_x_discrete(name = "Attack")+
  scale_y_discrete("Duration")
```

- Observación sobre como **"Flag"** es un buen predictor. Flag= "REG" y "S0" es tipo "DoS"  
```{r eda5, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
qplot(Service,Flag,colour=Attack,data=data)
```

- Observación sobre como para **'Duration'** mayor de 30.000 se puede ver un **'probe'**, la duración misma ya es un fuerte predictor  
```{r eda6, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
qplot(Duration,SrcBytes,colour=Attack,data=data)
```

- Observación sobre como **ProtocolType="tcp"** tiene "DoS" un fuerte predictor del tipo **"DoS"**.  
```{r eda7, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
qplot(Service,ProtocolType,colour=Attack,data=data)
```

- Observación NO hay una clara identificación con **'Flag'**  
```{r eda8, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
qplot(Flag,Land,colour=Attack,data=data)
```

- Observación: **'SerrorRate'** y **'SrvSerrorRate'**=0 or 1 es tipo **"Dos"** y 'SerrorRate' entre 0.25 a 0.5 es un "probe"  
```{r eda9, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
qplot(SerrorRate,SrvSerrorRate,colour=Attack,data=data)
```

- Observación: con **'SrcBytes'** para duración mayor de 30000 puede ser un 'probe'  
```{r eda10, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
qplot(Duration,SrcBytes,colour=Attack,data=data)
```

- Resultado: claramente **'Flag'** is un potente predictor para incursiones de tipo **"DoS"**  
```{r eda11, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE, results='hide'}
A <- table(data$Flag,data$Attack)
B <- round(prop.table(A)*100,1)
kable(B, caption = "Resultado por tipo de Flag") %>%
    kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F)
```
`r round(prop.table(B)*100,1)`

## Enriquecimiento del **'Dataset Muestra'**:  

Con el objeto de dotar de mayor utilidad a un equipo de SOC o responsable de la cyberdefensa que recibiera las alertas automáticamente generadas por un sistema entrenado equivalente al usado en este documento, se estudia como podría mejorarse y aportar mayor Valor Añadido a la información resultante.  
A nivel de ejemplo, se podría mejorar el Dataset ya una vez entrenado el modelo, añadiendo la correspondencia de la variable **'Attack'** con las tácticas del estándar de Mitre ATT&CK y poblar el Dataset con las variables relacionadas con su ID y el ID CWE de la debilidad expuesta, añadiendo más valor al receptor de la información o alerta.  

Nota: la clasificación ha sido obtenida de fuentes de búsqueda como _Google y ChatGPT 3_, en algunos tipos no se ha podido identificar claramente etiquetándolos como **'NotFound'**, estos casos podrían intentarse acabar de identificar usando el ejemplo visto en clase con Node4J, o con bibliotecas mas especializadas. _(se emplazaría la continuación y mejora del estudio para futuras ampliaciones de la práctica)_

```{r add_standard, cache=TRUE, message=FALSE}
#### 1. carga limpio el Dataset
data_r <- read.csv("Book2.csv",header=T)
#data_r <- data

#### 2. me quedo solo con las variables numéricas en nuevo data_r
#numeric_cols <- sapply(data_r, is.numeric)
#data_r <- data_r[, numeric_cols == TRUE] 
# elimino variables con Varianza zero y nzv, #eliminará la variable NumOutboundCmds
#variance <- nearZeroVar(data_r, saveMetrics = T)
#data_r <- data_r[, !(variance$zeroVar | variance$nzv)]
# Se añade la variable numerica SrcBytes ya que detectado mejora la predicción
#data_r$SrcBytes <- data$SrcBytes

#### 3. columna con alta correlación entre ellas, se pueden eliminar
#columns_to_remove <- c("DstHostSameSrvRate", "DstHostSrvRerrorRate", "DstHostRerrorRate", "RerrorRate", "DstHostSrvSerrorRate", "DstHostSerrorRate", "SrvSerrorRate")
#data_r <- data_r[, setdiff(names(data_r), columns_to_remove)]

#### 4. Se añade la variable numerica SrcBytes ya que detectado mejora la predicción
#data_r$SrcBytes <- data$SrcBytes
data_r$Attack <- as.factor(data_r$Attack)

#### 5. Definir las tácticas de ATT&CK y las variables relacionadas con su ID según estándard MITRE y CWE
tacticas_attck <- list(
  "Reconnaissance" = list(c("nmap.", "satan.", "mscan.", "snmpgetattack.", "named.", "ipsweep.", "xsnoop", "xclock.", "saint.","snmpguess.","portsweep"), "T0497", "CWE-200"),
  "Delivery" = list(c("smurf.", "neptune.", "teardrop."), "T1496", "CWE-693"),
  "Exploitation" = list(c("buffer_overflow.", "rootkit.", "loadmodule."), "T1203", "CWE-119"),
  "Privilege Escalation" = list(c("ftp_write.", "multihop.", "phf."), "T1068", "CWE-732"),
  "Command and Control" = list(c("back.", "land.", "imap."), "T1071", "CWE-1002"),
  "Lateral Movement" = list(c("guess_passwd.", "warezmaster.", "warezclient."), "T1070", "CWE-611"),
  "Exfiltration" = list(c("ftp_write.", "imap.", "spy."), "T1048", "CWE-359"),
  "Persistence" = list(c("rootkit.", "perl.", "loadmodule."), "T1547", "CWE-798"),
  "Defense Evasion" = list(c("ftp_write.", "nmap", "phf."), "T1222", "CWE-200"),
  "Denial of Service" = list(c("smurf.", "neptune.", "teardrop.", "apache2.","pod."), "T1498", "CWE-400"),
  "Normal" = list(c("normal."),"none","none"),
  "NotFound" = list(c("httptunnel.","processtable.","mailbomb.","sqlattack.","worm.","udpstorm.","xterm.","ps.","sendmail.","xlock."),"notfound","notfound")
)

# Función para clasificar la táctica de ATT&CK según las variables del dataset y añadir los IDs correspondientes
clasificar_tactica_attck <- function(registro) {
  for (tactica in names(tacticas_attck)) {
    variables <- tacticas_attck[[tactica]][[1]]
    id_attck <- tacticas_attck[[tactica]][[2]]
    id_cwe <- tacticas_attck[[tactica]][[3]]
    #if (any(registro %in% variables)) {
    if (any(grepl(paste(variables, collapse = "|"), registro))) {
      return(list(Tactica = tactica, ATTCK= id_attck, CWE = id_cwe))
    }
  }
  return(list(Tactica = "Unknown", ATTCK= "Unknown", CWE = "Unknown"))
}

# Aplicar la clasificación a cada registro del dataset y añadir los IDs correspondientes
resultados <- t(sapply(as.character(data_r$Attack), clasificar_tactica_attck))
colnames(resultados) <- c("Tactica", "ID_Tactic", "ID_CWE")

# Unir los resultados al dataset original
data_r <- cbind(data_r, as.data.frame(resultados))
data_r$Tactica <- as.character(data_r$Tactica)
data_r$ID_Tactic <- as.character(data_r$ID_Tactic)
data_r$ID_CWE <- as.character(data_r$ID_CWE)
data_r$Attack <- as.factor(data_r$Attack)

# Mostrar los valores de Attack que no han podido ser clasificados
unclassified_attacks <- data_r$Attack[data_r$Tactica == "Unknown"]

if (length(unclassified_attacks) > 0) {
  cat("Valores de Attack no clasificados:",length(unclassified_attacks),"\n")
  
  # Crear una tabla de valores no clasificados y contar el total de casos por cada valor
  unclassified_table <- table(unclassified_attacks)
  # Filtrar la tabla para incluir solo los valores con más de 1 caso no clasificado
  unclassified_table_filtered <- unclassified_table[unclassified_table > 0]
  
  # Ordenar la tabla por Attack
  unclassified_table <- unclassified_table[order(names(unclassified_table))]
  
  # Mostrar la tabla ordenada y el total de casos por cada valor
  #print(unclassified_table)
} else {
  cat("Todos los valores de Attack han sido clasificados correctamente.")
}

# Gráfico de las partes y relaciones del dataset final
ggplot(data_r, aes(x = Tactica, y = Attack, fill = Tactica)) +
  geom_tile(color = "white") +
  labs(x = "Táctica ATT&CK", y = "Ataque", fill = "Táctica ATT&CK") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) +
  guides(fill = guide_legend(title = "Táctica ATT&CK")) +
  scale_fill_brewer(palette = "Set3")

# Crear la tabla con los resultados de la clasificación y agrupar por Táctica
tabla_relacion <- data_r %>%
  group_by(Tactica) %>%
  summarise(ID_Tactic = unique(ID_Tactic),
            ID_CWE = unique(ID_CWE))

# Mostrar la tabla
kable(tabla_relacion, caption = "Relación de Táctica con IDs y CWE") %>%
    kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F)
```

#### Testeo de la eficacia de las nuevas variables.  {-}
_se dispone del código pero no se evalua por no aportar mucha información relevante_
```{r add_tunning_RF_model_group_tests, eval=FALSE, cache=TRUE}
rf_trees_fin <- rf_trees #200
part_fin <- 0.5 
set.seed(123)

data_r$Tactica <- as.factor(data_r$Tactica)

# Prepara la división entre training y testing
inTrain_fin <- createDataPartition(y=data_r$Tactica, p=part_fin, list=FALSE)
training_fin <- data_r[inTrain_fin,]
testing_fin <- data_r[-inTrain_fin,]
prop.table(table(training_fin$Tactica))
prop.table(table(testing_fin$Tactica))

# Entrenar el modelo de Random Forest
control <- rfeControl(functions=rfFuncs, method="cv", number=10)

start_time <- Sys.time()
rf_fin_model <- randomForest(Tactica ~ ., 
                          data = training_fin,
                          mtry = 5,
                          importance = TRUE,
                          rfeControl=control,
                          ntree = rf_trees_fin)
end_time <- Sys.time()
elapsed_time_fin <- round((end_time - start_time), 2)
rf_fin_pred <- predict(rf_fin_model, testing_fin)

cm_fin <- confusionMatrix(rf_fin_pred, testing_fin$Tactica)

#predictors(rf_fin_model)
plot(rf_fin_model)
heatmap(cm_fin$table)

rf_fin_accuracy <- round(cm_fin$overall[1], 4)*100
rf_fin_kappa <- round(cm_fin$overall[2], 4)*100
resultado_final <- data.frame( Accuracy= as.numeric(rf_fin_accuracy),
                               Kappa= as.numeric(rf_fin_kappa),
                               Tiempo= as.numeric(elapsed_time_fin))

print(resultado_final)

# Crear una nueva columna "match" en la tabla valid
valid <- testing_fin %>%
  mutate(Attack = as.character(Tactica),
         pred = as.character(rf_fin_pred),
         match = Attack == pred)

# Calcular el número total de registros por variable Attack
total_per_attack <- table(valid$Tactica)

# Calcular el número de aciertos por variable Attack
aciertos_per_attack <- tapply(valid$match, valid$Tactica, function(x) sum(x))

# Calcular el número de fallos por variable Attack
fallos_per_attack <- total_per_attack - aciertos_per_attack

# Calcular el Accuracy por variable Attack
accuracy_per_attack <- round((aciertos_per_attack / total_per_attack *100), 2)

# Crear la tabla tabla_fin con fallos, aciertos y Accuracy por variable Attack
tabla_fin <- data.frame(Attack = names(total_per_attack),
                        Aciertos = as.integer(aciertos_per_attack),
                        Fallos = as.integer(fallos_per_attack),
                        Accuracy = as.numeric(accuracy_per_attack))

# Ordenar la tabla_fin por Accuracy y Total Aciertos
tabla_fin <- tabla_fin %>%
  arrange(desc(Accuracy), desc(Aciertos))

# Mostrar la tabla tabla_fin actualizada
kable(tabla_fin, caption = "Resultado por tipo de Attack") %>%
    kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F)
```
# Appendix: Muestra todo el código fuente usado para este informe

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE, class.source = 'fold-show'}
```





