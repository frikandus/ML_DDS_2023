---
title: "Práctica Final en Data Driven Security"
author: "Grup CC: Toni Jordan Y Joan Dalmau"
date: "Junio de 2023"
output:
  html_document:
    toc: yes
    number_sections: yes
    toc_float: true
    toc_collapsed: true
    toc_depth: 4
    df_print: paged
    code_folding: hide
    theme: spacelab
---

```{r setup, results='hide'}
# Opciones de configuración de knitr
options(knitr.kable.NA = '')
options(knitr.table.format = "html")
knitr::opts_chunk$set(echo = FALSE, fig.align = 'center')

# Cargar paquetes necesarios
library(readr)
library(caret)        #modelos ML
library(randomForest) #RandomForest
library(nnet)         #Neuronal
library(e1071)        #Naive Bayes
library(dplyr)
library(ggplot2)
library(doParallel)   #paralelizacion
library(corrplot)
library(class)
library(data.table)
library(knitr)
library(kableExtra)
library(foreach)      #paralelizacion
library(grid)

#Constantes utilizadas en el programa
rf_trees <- 200    #número máximo de arboles para RandomForest Final
limite <- 30       #número mínimo de muestras para considerar el mantener una variable como autónoma
```

# Objetivo

El objetivo de esta práctica es realizar un estudio de un subconjunto del Dataset KDD CUP 99 para determinar cuál es el mejor conjunto de variables que podemos usar en un entrenamiento de Machine Learning de clasificación y finalmente conseguir un juego de datos y modelo de entrenamiento que mejore el valor obtenido por el script del enunciado.

Para llevar a cabo este estudio, se dispone de dos archivos de datos con incidencias etiquetadas, una codificación de ejemplo en R, información sobre los estándares Mitre de ATT&CK y unas primeras conclusiones sobre los datos.

## Packages
En esta práctica se utilizarán los siguientes paquetes de R:

```{r load_packages, message=FALSE, warning=FALSE, results='hide'}
mypackages <- c("randomForest", "nnet", "readr", "caret", "e1071","dplyr","ggplot2", "doParallel","data.table", "kableExtra","corplot","class", "knitr", "tidyr", "grid")

# Crear un data.table con los paquetes
pa<-data.table(mypackages)

# Dividir el data.table en tres partes
cc<-as.integer(length(mypackages)/3)
pa1<-pa[1:cc]
pa2<- pa[(cc+1):(2*cc)]
pa3<- pa[(2*cc+1):length(mypackages)]
```

```{r pack, message=FALSE, warning=FALSE}
kable(list(pa1, pa2, pa3),col.names = NULL, caption = "Necesarios:") %>%
    kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F)
```
## Esquema argumental del documento:

### Validación y pre-porcesado del "Dataset Muestra" respecto al "Dataset Global" entregado  {-}
- Estudio del Dataset Muestra y su contenido  
- Validación de duplicados en el Dataset Muestra  
- Validación de proporciones de la variable "Attack" en el Dataset Muestra  
- Posibilidad de aumentar el número de muestras con el Dataset Global  
- Tratamiento de variables con bajas muestras  

### Selector de variables  {-}
- Criterios de selección y competividad de los precursores con Random Forest  
- Comparativa de diferentes modelos de Machine Learning  
- Optimización del modelo de Machine Learning y conclusiones  

### Mejora de la información y valor añadido  {-}
- Estudios EDA de las variables  
- Información agregada MITRE ATT&CK y CWE  

# Análisis y preprocesamiento de los conjuntos de datos  

En esta sección, se realizará un análisis exploratorio de los conjuntos de datos "Dataset Global" y "Dataset Muestra". Además, se llevará a cabo un preprocesamiento de los datos para asegurarnos de que sean adecuados para su uso en el entrenamiento de modelos de Machine Learning.  

## Carga de los conjuntos de datos  

Comenzamos cargando los conjuntos de datos "Dataset Global" y "Dataset Muestra" en R.  

```{r read_dataset, echo=TRUE, cache=TRUE, class.source = 'fold-show'}
data_full <- read_csv("Book1.csv",
                  col_types = cols(SrcBytes = col_integer(),
                                   DstBytes = col_integer(), Land = col_integer(),
                                   WrongFragment = col_integer(), Urgent = col_number(),
                                   Hot = col_number(), NumFailedLogin = col_integer()))
data <- read.csv("Book2.csv", header=T)
```

### Exploración de los conjuntos de datos  

A continuación, realizaremos un análisis exploratorio de los conjuntos de datos para comprender su estructura y contenido.  

```{r explore_data, eval=TRUE, cache=TRUE}
# Visualizar las primeras filas del Dataset Global
head(data_full)

# Visualizar las primeras filas del Dataset Muestra
head(data)
```

El conjunto de datos "Dataset Global" contiene las siguientes columnas: SrcBytes, DstBytes, Land, WrongFragment, Urgent, Hot y NumFailedLogin.... Cada fila representa un incidente.  

El conjunto de datos "Dataset Muestra" contiene las mismas columnas que el conjunto de datos "Dataset Global" y se utiliza como una muestra de incidencias para nuestro estudio.  

### Validación y preprocesamiento del conjunto de datos de muestra  

En esta sección, se realizarán algunas validaciones y preprocesamientos en el conjunto de datos de muestra para asegurarnos de que cumpla con nuestros requisitos.  

#### Estudio del conjunto de datos de muestra y su contenido  {-}

A continuación, se realizará un estudio más detallado del conjunto de datos de muestra y su contenido.  

```{r study_sample_data, echo=TRUE, eval=FALSE, results='hide', class.source = 'fold-show'}
# Resumen del conjunto de datos de muestra
summary(data)

# Tipos de datos de las columnas del conjunto de datos de muestra
str(data)

dim(data)
```

El conjunto de datos de muestra tiene **`r nrow(data)`** filas y **`r ncol(data)`** columnas. Se distribuyen en los siguientes tipos:

```{r 0_study_data, cache=TRUE}
# Contar el número de variables cualitativas, cuantitativas y factor
num_qualitative <- sum(sapply(data, is.character))
num_quantitative <- sum(sapply(data, is.numeric))
num_factor <- sum(sapply(data, is.factor))
  
# Crear una tabla resumen
summary_table <- data.frame(Tipo = c("Cualitativa", "Cuantitativa", "Factor"),
                            Numero = c(num_qualitative, num_quantitative, num_factor))

# Imprimir la tabla resumen usando la función knitr::kable()
kable(summary_table, caption = "Clasificación por tipos de Variables") %>%
    kable_styling(bootstrap_options = c("striped"), full_width = F)
```
Contiene **`r summary_table$Numero[2]`** variable numéricas cuantitativas y **`r summary_table$Numero[1]`** variables cualitativas.  
```{r 0c_study_data, results='hide', cache=TRUE}
# Obtener solo las variables cualitativas y los valores de estas
qualitative_vars <- select_if(data, is.character)
distinct_values <- lapply(qualitative_vars, unique)

# Crear una tabla resumen
summary_table2 <- data.frame(Variable = character(), Valores = character(), Categorias = integer(), stringsAsFactors = FALSE)

# Llenar la tabla resumen con los valores diferentes y el número de categorías de cada variable cualitativa
llista <- ""
for (i in 1:length(distinct_values)) {
  variable <- names(distinct_values[i])
  values <- paste(distinct_values[[i]], collapse = ", ")
  num_categories <- length(distinct_values[[i]])
  llista<- as.character(paste(llista,variable,","))
  summary_table2 <- rbind(summary_table2, data.frame(Variable = variable, Categorias = num_categories, Valores = values))
}
### Ordenar la tabla resumen por nombre de variable
summary_table2 <- summary_table2 %>% arrange(Variable)
```

Las columnas cualitativas son: **`r llista`** que representa la variable factor.  

```{r 0d1_study_data, cache=TRUE}
# Imprimir la tabla resumen
kable(summary_table2, caption = "Clasificación por Variables cualitativa") %>%
    kable_styling(bootstrap_options = c("striped", "condensed"))
```
```{r 0d2_study_data, results='hide', fig.align='center', fig.cap='Variables Cualitativas', cache=TRUE}
# Crear un gráfico explicativo por cada variable cualitativa
num_variables <- nrow(summary_table2)
num_rows <- 2  # Número de filas en la matriz de gráficos
num_cols <- ceiling(num_variables / num_rows)  # Número de columnas en la matriz de gráficos

# Establecer la disposición de los gráficos
layout(matrix(1:num_variables, nrow = num_rows, ncol = num_cols))

for (i in 1:num_variables) {
  variable <- summary_table2$Variable[i]
  plot_data <- table(data[[variable]])
  plot <- barplot(plot_data, main = paste("Muestras de ", variable),
                  xlab = "Valor Cualitativo", ylab = "Número de Muestras",
                  col = "skyblue", border = "white")
  print(plot)
}

# Restaurar la configuración del dispositivo gráfico
layout(1)
```

### Validación de duplicados en el conjunto de datos de muestra

Vamos a validar si el conjunto de datos de la muestra contiene filas duplicadas y, en caso afirmativo, eliminaremos las filas duplicadas.
```{r 1b_study_data, results='hide', cache=TRUE}
# Calcular el número de muestras duplicadas o iguales en el Dataset
duplicates <- data %>%
  group_by_all() %>%
  filter(n() > 1) %>%
  summarise(Num_Duplicates = n()) %>%
  arrange(desc(Num_Duplicates))
```
```{r 1bb_study_data, eval=FALSE, echo=TRUE, cache=TRUE, class.source = 'fold-show'}
# Calcular el número de muestras duplicadas o iguales en el Dataset
duplicates <- data %>%
  group_by_all() %>%
  filter(n() > 1) %>%
  summarise(Num_Duplicates = n()) %>%
  arrange(desc(Num_Duplicates))
```

```{r 0b3_study_data, cache=TRUE}
# Imprimir la tabla ordenada
cat("Número de muestras duplicadas en Dataset:", nrow(duplicates), "\n")
# Eliminar las muestras duplicadas y conservar solo una muestra de ellas
kdd_data_unique <- distinct(data, .keep_all = TRUE)
# Calcular el número de muestras duplicadas eliminadas
duplicates <- nrow(data) - nrow(kdd_data_unique)
# Imprimir el número de muestras duplicadas eliminadas
cat("Número de muestras duplicadas eliminadas:", duplicates, "\n")
rm(kdd_data_unique) #eliminamos dataset temporal
```
Se confirma que el DATASET de trabajo es correcto y no tiene muestras duplicadas.
```{r 2a_study_data, cache=TRUE}
# Constantes: valor extremo de la diferencia de porcetage permitido XX% y cantidad mínima de muestras
difer_n <- 3
cant_min <- 1000
```
### Con el siguiente estudio se pretende analizaa el Dataset Muestra y el Dataset Global 
El objetivo es ver si podemos añadir muestras en el Dataset Global para mejorar el Dataset de trabajo, para ello se observa si hay muestras diferentes que podamos extraer de aquellos tipos de ataque con un número inferior a **`r cant_min `** muestras en el Dataset de trabajo.  

Eliminamos filas duplicados dejando filas únicas en el DATASET FULL y comparamos los dos juegos de datos:  
```{r 2b_study_data, echo=TRUE, cache=TRUE, class.source = 'fold-show'}
# Eliminar las muestras duplicadas y conservar solo una muestra de ellas
kdd_data_full_unique <- distinct(data_full, .keep_all = TRUE)
```
```{r 2c_study_data, cache=TRUE}
# Calcular el número de muestras duplicadas eliminadas
duplicates <- nrow(data_full) - nrow(kdd_data_full_unique)
```
```{r 2d_study_data, echo=TRUE, cache=TRUE}
data_full <- kdd_data_full_unique
```
```{r 2e_study_data, cache=TRUE}
rm(kdd_data_full_unique) #eliminamos el dataset temporal
# Imprimir el número de muestras duplicadas eliminadas
cat("Número de muestras duplicadas eliminadas en Dataset Full:", duplicates, "\n")

# Calcular la frecuencia y porcentaje de casos por valor de Attack
attack_counts_full <- data_full[data_full$Attack != "normal.", ] %>% 
  count(Attack) %>%
  mutate(Percentage_Full = round(n/sum(n) * 100, 2)) %>%
  arrange(desc(Percentage_Full))

attack_counts <- data[data$Attack != "normal.", ] %>% 
  count(Attack) %>%
  mutate(Percentage = round(n/sum(n) * 100, 2)) %>%
  arrange(desc(Percentage))

# Crear una tabla combinada con los totales y porcentajes
attack_table <- merge(attack_counts_full, attack_counts, by = "Attack", suffixes = c("_Full", "_Ini"))
attack_table <- attack_table[order(attack_table$n_Full, decreasing = TRUE),]

# Calcular la diferencia entre Diponible_Full y Disponible_Ini
attack_table$Disponibles <- attack_table$n_Full-attack_table$n_Ini

# Filtrar los casos con diferencia mayor al XX%
filtered_attack_table_n <- attack_table[attack_table$Disponibles > 0, ]

# Imprimir la tabla comparativa
kable(attack_table, caption = "Comparativa número de attaques por cada Dataset") %>%
    kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F)

# Imprimir la tabla de casos con diferencia mayor al XX%
cat("Número de nuevas muestras disponibles en Dataset Full:", nrow(filtered_attack_table_n), "\n")
rm(data_full)  #eliminamos data_full, no es util
```

Con el siguiente estudio se concluye que el Dataset de trabajo es ya el Dataset Global filtrado y no es posible poblar el Dataset de trabajo con mas muestras, para ello se debería descargar nuevas muestras desde el repositorio:   

- Source data [KDD Cup 1999 Data Data Set](https://archive.ics.uci.edu/ml/datasets/kdd+cup+1999+data)  

- Finalmente se elimina el 'DataSet Full'.  
```{r 3_study_data, fig.align='center', fig.cap='Comparativa Data_Full<>Data', cache=TRUE}
# Crear un gráfico de barras comparativo
ggplot(attack_table, aes(x = Attack)) +
  geom_bar(aes(y = n_Full, fill = "Data_Full"), stat = "identity", just = 0) +
  geom_bar(aes(y = n_Ini, fill = "Data"), stat = "identity", just = 1) +
  labs(title = "Número de casos por valor de Attack", x = "Attack", y = "Muestras") +
  scale_fill_manual(values = c("blue", "red"), guide = guide_legend(title = "Dataset")) +
  ggtitle("Diferencia de Muestras en Data_Full vs Data") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## Tratamiento de las muestras residuales
```{r  4_study_data, fig.align='center', fig.cap='Agrupando variables residuales', out.width='50%', fig.show='hold', cache=TRUE}
# Crear un gráfico de barras del porcentaje de casos por valor de Attack sin agrupar
ggplot(attack_counts, aes(x = reorder(Attack, -Percentage), y = Percentage)) +
  geom_bar(stat = "identity", fill = "blue") +
  labs(title = "Porcentaje de casos por valor de Attack (original)",
       x = "Attack",
       y = "Porcentaje de casos") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Reemplazar valores inferiores a XX por "other" en el dataset data
data$Attack <- ifelse(data$Attack %in% attack_table$Attack[attack_table$n_Ini < limite], "other", data$Attack)

# Filtrar los casos que no tienen el valor "normal."
data_filtered <- data %>% filter(Attack != "normal.")

# Contar la frecuencia de los valores en la columna "Attack"
frecuencia_attack <- sort(table(data_filtered$Attack), decreasing = TRUE)

# Calcular el porcentaje de casos por valor de Attack
attack_counts <- data_filtered %>% 
  count(Attack) %>%
  mutate(Percentage = round(n/sum(n) * 100, 2)) %>%
  arrange(desc(Percentage))

# Crea una tabla ordenada con los totales
attack_table_final <- data.frame(
  Attack = names(frecuencia_attack), 
  Total = as.numeric(frecuencia_attack), 
  Porcentaje = as.numeric(attack_counts$Percentage)
)
attack_table_final <- attack_table_final[order(attack_table_final$Total, decreasing = TRUE), ]

# Imprimir la tabla comparativa
kable(attack_table_final, caption = "Comparativa número de attaques nuevo Dataset") %>%
    kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F)

# Crear un gráfico de barras del porcentaje de casos por valor de Attack una vez agrupado
ggplot(attack_counts, aes(x = reorder(Attack, -Percentage), y = Percentage)) +
  geom_bar(stat = "identity", fill = "blue") +
  labs(title = "Porcentaje de casos por valor de Attack (agrupado)",
       x = "Attack",
       y = "Porcentaje de casos") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r 4b_study_data,}

```

Aunque la creación de un buen modelo debe entenderse como un proceso iterativo, en el que se van ajustando y probando distintos modelos, existen ciertas pistas que pueden ayudar a realizar una selección inicial adecuada.

Si dos variables numéricas están muy correlacionadas, añaden información redundante al modelo, por lo tanto, no conviene incorporar ambas. Si esto ocurre, se puede: excluir aquella que, acorde al criterio del analista, no está realmente asociada con la variable respuesta; o combinarlas para recoger toda su información en una única nueva variable, por ejemplo, con un PCA.

Si una variable tiene varianza igual o próxima a cero (su valor es el mismo o casi el mismo para todas las observaciones) añade al modelo más ruido que información, por lo que suele ser conveniente excluirla.

Si alguno de los niveles de una variable cualitativa tiene muy pocas observaciones en comparación a los otros niveles, puede ocurrir que, durante la validación cruzada o bootstrapping, algunas particiones no contengan ninguna observación de dicha clase (varianza cero), lo que puede dar lugar a errores. En estos casos, suele ser conveniente eliminar las observaciones del grupo minoritario (si es una variable multiclase), eliminar la variable (si solo tiene dos niveles) o asegurar que, en la creación de las particiones, se garantice que todos los grupos estén representados en cada una de ellas.

## Selección de Predictores, (PCA)

Sección de carga de los diferentes modelos de subset por variables
```{r 2_feature_selection, cache=TRUE}
# Enunciado de la práctica
data1_original <- data[,c("SrcBytes", "DstBytes", "Land", "WrongFragment", "Urgent", "SameSrvRate", "LoggedIn",  "DstHostSameSrvRate", "DstHostSrvCount","Flag","Attack" )]
data1_original$Attack <- as.factor(data1_original$Attack)
# pdf de soporte
data1_pdf <- data[,c("SrcBytes", "DstBytes", "DstHostSameSrvRate", "Count", "DstHostDiffSrvRate","Attack" )]
data1_pdf$Attack <- as.factor(data1_pdf$Attack)
# Criterio teórico de los expertos en Networking
data1_teorico <- data[,c("SrcBytes", "DstBytes", "Land", "WrongFragment", "Urgent", "Hot","NumFailedLogin","Attack" )]
data1_teorico$Attack <- as.factor(data1_teorico$Attack)
```

### modulo de selección de las variables finales por criterios puramente estadísticos
```{r 2_2_feature_selection, cache=TRUE}
# 1. Criterio de la Varianza nula o cerca del cero
# "SrcBytes", "DstBytes", "Count", "DstHostSameSrvRate", "DstHostDiffSrvRate", "DstHostSrvDiffHostRate", "LoggedIn","SrvCount", 
# "SerrorRate", "SrvSerrorRate", "RerrorRate", "SrvRerrorRate", "DiffSrvRate","SrvDiffHostRate", "DstHostSrvCount", 
# "DstHostSameSrcPortRate", "DstHostSerrorRate", "DstHostSrvSerrorRate", "DstHostRerrorRate", "DstHostSrvRerrorRate", "NumOutboundCmds" 

# me quedo solo con las variables numéricas en nuevo data1 para calcular varianzas
numeric_cols <- sapply(data, is.numeric)
data1 <- data[, numeric_cols == TRUE] 
# elimino variables con Varianza zero "NumOutboundCmds" y nzv 
variance <- nearZeroVar(data1, saveMetrics = T)
data1 <- data1[, !(variance$zeroVar | variance$nzv)]
# Filtrar los valores de zeroVar y nzv
#variance_filtered <- variance[!(variance$zeroVar | variance$nzv), ]
variance_filtered <- variance[variance$zeroVar | variance$nzv, ]

# Se añade la variable numerica SrcBytes ya que detectado mejora la predicción
data1$SrcBytes <- data$SrcBytes

# Imprimir la tabla resumen
kable(variance_filtered, caption = "Variables a eliminar por la baja Varianza") %>%
    kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F)

# Buscamos variables correladas para eliminarlas
correlation <- cor(data1)
highlyCorrelated <- findCorrelation(correlation, verbose=F, names=T)  #selecciona a partir del 0.9 de indice de correlación

# Convertir highlyCorrelated en una única fila
highlyCorrelated_row <- paste("variables a eliminar por correlación:", paste(highlyCorrelated, collapse = ", "))
highlyCorrelated_row

corrplot(correlation, method="circle", na.label= '.')

# Eliminamos filas 
data1 <- data1[, setdiff(names(data1), highlyCorrelated)]

# Se añade la variable numerica SrcBytes ya que detectado mejora la predicción
data1$SrcBytes <- data$SrcBytes
# Añadir la variable factor "Attack" al dataset filtrado
data1$Attack <- as.factor(data$Attack)
```
#### Se toman los cuatro juegos de variables para generar cuatro nuevos dataset con los siguientes tamaños:  

```{r 2_1bb_feature_selection, results='hide', cache=TRUE}
divide <- 0.1  # 10%, toma mínima de muestras para acelerar el cálculo

set.seed(123)

# Crear partición de entrenamiento y prueba para cada dataset
datasets <- list(
  Estadistico = data1,
  Enunciado = data1_original,
  Ejemplo_pdf = data1_pdf,
  Teorico_net = data1_teorico
)

particion <- lapply(datasets, function(data) {
  inTrain <- createDataPartition(y = data$Attack, p = divide, list = FALSE)
  list(training = data[inTrain,], testing = data[-inTrain,])
})

# Función para ajustar un modelo de random forest y obtener las predicciones
ajustar_rf <- function(data) {
  start_time <- Sys.time()
  model <- randomForest(Attack ~ ., data = data$training, ntree = rf_trees, na.action = na.fail)
  end_time <- Sys.time()
  elapsed_time <- round((end_time - start_time), 2)
  pred <- predict(model, data$testing)
  cm <- confusionMatrix(pred, data$testing$Attack)
  accuracy <- round(cm$overall[1], 4) * 100
  kappa <- round(cm$overall[2], 4) * 100
  list(model = model, pred = pred, accuracy = accuracy, kappa = kappa, cm = cm, tiempo = elapsed_time)
}

# Ajustar modelos y obtener resultados para cada dataset
resultados <- lapply(particion, ajustar_rf)

# Crear tabla de resultados
tabla_resultados <- data.frame(
  Variable = names(resultados),
  Accuracy = sapply(resultados, function(res) res$accuracy),
  Kappa = sapply(resultados, function(res) res$kappa),
  Tiempo = sapply(resultados, function(res) res$tiempo)
)
```
```{r 2_1b_feature_selection, cache=TRUE}
# Imprimir la tabla de resultados
kable(tabla_resultados, caption = "Comparativa por juego de predictores") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)
```
```{r 2_1c_feature_selection, cache=TRUE, fig.align='center', fig.cap='validando variables', out.width='50%', fig.show='hold', results='hide'}
# Función para generar el gráfico y mapa de calor para cada modelo
generar_grafico <- function(result, cm, caption) {
  plot(result$model, main= caption)
  heatmap(cm$table)
  title(caption)
}

# Generar gráficos y mapas de calor para cada modelo
lapply(seq_along(resultados), function(i) generar_grafico(resultados[[i]], resultados[[i]]$cm, tabla_resultados$Variable[i]))
# Eliminar datasets y objetos temporales
rm(datasets, particion, resultados)
```

**Conclusión: nos quedaremos con la propuesta de variables púramente estadística**

### Compararemos ahora el juego de variables escogido en varios modelos de entranamiento para comprobar cual es mas óptimo  

```{r 2_3_other_model_tests, results='hide', fig.align='center', out.width='50%', fig.show='hold', cache=TRUE}
divide <- 0.1  # 10%, toma mínima de muestras para acelerar el cálculo

set.seed(123)
inTrain <- createDataPartition(y=data1$Attack, p=divide, list=FALSE)
training <- data1[inTrain,]
testing <- data1[-inTrain,]

# Función para calcular precisión y tiempo de ejecución
calculate_accuracy_time <- function(model, training, testing, method_name) {
  end_time <- Sys.time()
  elapsed_time <- round((end_time - start_time), 2)
  pred <- predict(model, testing)
  cm_model <- confusionMatrix(pred, testing$Attack)
  cm_accuracy <- round(cm_model$overall[1], 4)*100
  cm_kappa <- round(cm_model$overall[2], 4)*100
  heatmap(cm_model$table)
  title(method_name)
  list(Modelo = method_name, Accuracy = cm_accuracy, Kappa = cm_kappa, Tiempo = elapsed_time)
}

results <- list()

# Random Forest
start_time <- Sys.time()
rf_model <- randomForest(Attack ~ ., data = training, ntree = 100)
plot(rf_model, main="Random Forest")
results$rf <- calculate_accuracy_time(rf_model, training, testing, "Random Forest")

# Support Vector Machine
start_time <- Sys.time()
svm_model <- svm(Attack ~ ., data = training)
results$svm <- calculate_accuracy_time(svm_model, training, testing, "Support Vector Machine")

# CART (Classification and Regression Trees)
control <- trainControl(method = "cv", number = 2)
start_time <- Sys.time()
fit.cart <- train(Attack ~ ., data = training, method = "rpart", metric = "Accuracy", trControl = control)
results$cart <- calculate_accuracy_time(fit.cart, training, testing, "CART")

# KNN (K-Nearest Neighbors), me quedo con las variables numéricas
num_vars = sapply(training, is.numeric)
training_num = training[, num_vars]
num_vars = sapply(testing, is.numeric)
testing_num = testing[, num_vars]

start_time <- Sys.time()
knn_model <- knn(train = training_num, test = testing[, 1:13], cl = training$Attack, k = 5)
end_time <- Sys.time()
elapsed_time <- round((end_time - start_time), 2)
cm_model <- confusionMatrix(knn_model, testing$Attack)
heatmap(cm_model$table)
title("K-Nearest Neighbors")
results$knn <- list(Modelo = "K-Nearest Neighbors",
                    Accuracy = round(cm_model$overall[1], 4) * 100,
                    Kappa = round(cm_model$overall[2], 4) * 100,
                    Tiempo = elapsed_time)

# Naive Bayes
start_time <- Sys.time()
nb_model <- naiveBayes(Attack ~ ., data = training)
results$nb <- calculate_accuracy_time(nb_model, training, testing, "Naive Bayes")
```
```{r 2_3b_other_model_tests, cache=TRUE}
# Resultados
results_t <- data.frame(Modelo = c(results$rf$Modelo, results$svm$Modelo, results$cart$Modelo,
                                    results$knn$Modelo, results$nb$Modelo),
                      Accuracy = c(results$rf$Accuracy, results$svm$Accuracy, results$cart$Accuracy,
                                    results$knn$Accuracy, results$nb$Accuracy),
                      Kappa = c(results$rf$Kappa, results$svm$Kappa, results$cart$Kappa,
                                    results$knn$Kappa, results$nb$Kappa),
                      Tiempo = c(results$rf$Tiempo, results$svm$Tiempo, results$cart$Tiempo,
                                    results$knn$Tiempo, results$nb$Tiempo))

kable(results_t, caption = "Resultados por métodos de Clasificación") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)
```

### Entrenamiento con el Random Forest y connfiguración Final  
Se modifica el número de muestras en el dataset de entrenamiento y se busca ajustar parámetros, incluso añadir nuevas variables.
```{r 2_4_tunning_RF_model_tests, echo=TRUE, cache=TRUE}
rf_trees_fin <- rf_trees #200
part_fin <- 0.5 
set.seed(123)

# Añadir columna "Anomaly" al dataset data1
#data1$Anomaly <- ifelse(data1$Attack == "normal.", FALSE, TRUE)
#data1$Anomaly <- as.factor(data1$Anomaly)

data1$Attack <- as.factor(data1$Attack)

# Prepara la división entre training y testing
inTrain_fin <- createDataPartition(y=data1$Attack, p=part_fin, list=FALSE)
training_fin <- data1[inTrain_fin,]
testing_fin <- data1[-inTrain_fin,]
prop.table(table(training_fin$Attack))
prop.table(table(testing_fin$Attack))

# Entrenar el modelo de Random Forest
control <- rfeControl(functions=rfFuncs, method="cv", number=10)

start_time <- Sys.time()
rf_fin_model <- randomForest(Attack ~ ., 
                          data = training_fin,
                          mtry = 5,
                          rfeControl=control,
                          ntree = rf_trees_fin)
end_time <- Sys.time()
elapsed_time_fin <- round((end_time - start_time), 2)
rf_fin_pred <- predict(rf_fin_model, testing_fin)

cm_fin <- confusionMatrix(rf_fin_pred, testing_fin$Attack)

predictors(rf_fin_model)
plot(rf_fin_model)
heatmap(cm_fin$table)

resultado_final <- data.frame( Accuracy= as.numeric(round(cm_fin$overall[1], 4)*100),
                               Kappa= as.numeric(round(cm_fin$overall[2], 4)*100),
                               Tiempo= as.numeric(elapsed_time_fin))

knitr::kable(resultado_final, caption = "Resultado por de Clasificación por RandomForest") %>%
    kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F)

# Crear una nueva columna "match" en la tabla valid
valid <- testing_fin %>%
  mutate(Attack = as.character(Attack),
         pred = as.character(rf_fin_pred),
         match = Attack == pred)

# Calcular el número total de registros por variable Attack
total_per_attack <- table(valid$Attack)

# Calcular el número de aciertos por variable Attack
aciertos_per_attack <- tapply(valid$match, valid$Attack, function(x) sum(x))

# Calcular el número de fallos por variable Attack
fallos_per_attack <- total_per_attack - aciertos_per_attack

# Calcular el Accuracy por variable Attack
accuracy_per_attack <- round((aciertos_per_attack / total_per_attack *100), 2)

# Crear la tabla tabla_fin con fallos, aciertos y Accuracy por variable Attack
tabla_fin <- data.frame(Attack = names(total_per_attack),
                        Aciertos = as.integer(aciertos_per_attack),
                        Fallos = as.integer(fallos_per_attack),
                        Accuracy = as.numeric(accuracy_per_attack))

# Ordenar la tabla_fin por Accuracy y Total Aciertos
tabla_fin <- tabla_fin %>%
  arrange(desc(Accuracy), desc(Aciertos))

# Mostrar la tabla tabla_fin actualizada
knitr::kable(tabla_fin, caption = "Resultado por tipo de Attack") %>%
    kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F)
```

# EDA: Esta sección es para completar el estudio de los datos y sus relaciones

Categorias principales de intrusiones:

DOS: denial-of-service, e.g. syn flood;
R2L: unauthorized access from a remote machine, e.g. guessing password;
U2R: unauthorized access to local superuser (root) privileges, e.g., various ``buffer overflow'' attacks;
probing: surveillance and other probing, e.g., port scanning.

#### Observación: DstHostSameSrcPortRate tiene un ligero efecto en el tipo de intrusión, para "DstHostSameSrcPortRate" mayor a igual a 1 puede ser "probe" de "r2l"
```{r 3_1_eda1, echo=TRUE, cache=TRUE}
qplot(DstHostSameSrvRate,DstHostSrvCount,colour=Attack,data=data)
```
#### Plot mean attack duration and median attack duration.
```{r, cache=TRUE}
ggplot(data=data, aes(x=data$Attack, y=data$Duration, fill = data$Attack)) + 
  geom_bar(stat = "summary", fun.y = "mean")+scale_x_discrete(name = "Attack")+
  scale_y_continuous("Duration")+labs(title="Mean attack duration", fill=("Attack\n") )

#median attack duraction
ggplot(data=data, aes(x=data$Attack, y=data$Duration, fill = data$Attack)) + 
  geom_bar(stat = "summary", fun.y = "median")+scale_x_discrete(name = "Attack")+
  scale_y_continuous("Duration")+labs(title="Median attack duration", fill=("Attack\n") )
```
The graphs show that the average durations reflect the type of attack. 
In fact, a DoS attack has an average duration of zero since its goal is to make a physical device in the network unusable. In this way, the service does down and the average duration is almost zero.
Note that, a Probing attack, which should get as much information as possible about network security, has a large average duration.
While, only the User to Root attack (u2r) has a very high median. In fact, the durations of this attack are comparable to each other, while this does not happen for other types of attacks that have very variable duration between them.

#### Plot average duration of attacks based on the type of protocol.
```{r, cache=TRUE}
ggplot(data=data, aes(x=data$Attack, y=data$Duration, fill = data$ProtocolType)) + 
  geom_bar(stat = "summary", fun.y = "mean")+scale_x_discrete(name = "Attack")+
  scale_y_continuous("Duration")+ scale_fill_discrete(name = "Protocol type\n")+
  labs(title="Average duration of attacks based on the type of protocol" )
```

Como se puede observar en el gráfico, los tipos de ataques reflejan la duración promedio basada en el tipo de protocolo. De hecho, muchos ataques utilizan el protocolo TCP que se utiliza ampliamente para implementar diferentes servicios. El uso extensivo del protocolo UDP en casos normales es extraño, pero depende del tipo de solicitudes de servicio del usuario.

Observaciones individuales usando 'Duration', 'Attack' y 'protocol type'.
```{r, cache=TRUE}
p1 <- ggplot(data,aes(y = data$Duration, x = data$Attack)) +
  geom_point()
p1 +  geom_point(aes(color=data$ProtocolType))+
  labs(title="Duraction, attack and protocol type" , color ="Protocol type")+
  scale_x_discrete(name = "Attack")+
  scale_y_discrete("Duration")
```

#### Observatión: "Flag" es un buen predictor. Flag= "REG" y "S0" es tipo "DoS"
```{r eda2, echo=TRUE, cache=TRUE}
qplot(Service,Flag,colour=Attack,data=data)
```

#### Observación: Para duración mayor hay de 30000 se puede ver un 'probe', la duración misma es un fuerte predictor
```{r eda3, echo=TRUE, cache=TRUE}
qplot(Duration,SrcBytes,colour=Attack,data=data)
```

#### Observación: Para duración mayor 30000 puede ser un 'probe'
 Observación: ProtocolType "tcp" tiene "DOS" tipo de intrusion. Es un fuerte predictor del tipo "DoS".
```{r eda4, echo=TRUE, cache=TRUE}
qplot(Service,ProtocolType,colour=Attack,data=data)
```

#### Observación: No hay una clara identificación
```{r eda5, echo=TRUE, cache=TRUE}
qplot(Flag,Land,colour=Attack,data=data)
```

#### Observación: Para SerrorRate y SrvSerrorRate=0 or 1 es tipo "Dos" y SerrorRate entre 0.25 a 0.5 es un "probe""
```{r eda6, echo=TRUE, cache=TRUE}
qplot(SerrorRate,SrvSerrorRate,colour=Attack,data=data)
```

#### Observación: para duración mayor de 30000 puede ser un 'probe'
```{r eda7, echo=TRUE, cache=TRUE}
qplot(Duration,SrcBytes,colour=Attack,data=data)
```

#### Resultado: claramente Flag is un potente predictor para incrusiones de tipo "DoS"
```{r eda8, echo=TRUE, cache=TRUE}
A=table(data$Flag,data$Attack)
round(prop.table(A)*100,1)
```

#### Enriquecemos el Dataset con: las tácticas de ATT&CK y las variables relacionadas con su ID según estándard MITRE y el ID de CWE
```{r 3_2_add_standard, cache=TRUE}
#### 1. carga limpio el Dataset
data <- read.csv("Book2.csv",header=T)
data_r <- data

#### 2. me quedo solo con las variables numéricas en nuevo data_r
numeric_cols <- sapply(data_r, is.numeric)
data_r <- data_r[, numeric_cols == TRUE] 
# elimino variables con Varianza zero y nzv, #eliminará la variable NumOutboundCmds
variance <- nearZeroVar(data_r, saveMetrics = T)
data_r <- data_r[, !(variance$zeroVar | variance$nzv)]
# Se añade la variable numerica SrcBytes ya que detectado mejora la predicción
data_r$SrcBytes <- data$SrcBytes

#### 3. columna con alta correlación entre ellas, se pueden eliminar
columns_to_remove <- c("DstHostSameSrvRate", "DstHostSrvRerrorRate", "DstHostRerrorRate", "RerrorRate", "DstHostSrvSerrorRate", "DstHostSerrorRate", "SrvSerrorRate")
data_r <- data_r[, setdiff(names(data_r), columns_to_remove)]

#### 4. Se añade la variable numerica SrcBytes ya que detectado mejora la predicción
data_r$SrcBytes <- data$SrcBytes
data_r$Attack <- as.factor(data$Attack)

#### 5. Definir las tácticas de ATT&CK y las variables relacionadas con su ID según estándard MITRE y CWE
tacticas_attck <- list(
  "Reconnaissance" = list(c("nmap.", "satan.", "mscan.", "snmpgetattack.", "named.", "ipsweep.", "xsnoop", "xclock.", "saint.","snmpguess.","portsweep"), "T0497", "CWE-200"),
  "Delivery" = list(c("smurf.", "neptune.", "teardrop."), "T1496", "CWE-693"),
  "Exploitation" = list(c("buffer_overflow.", "rootkit.", "loadmodule."), "T1203", "CWE-119"),
  "Privilege Escalation" = list(c("ftp_write.", "multihop.", "phf."), "T1068", "CWE-732"),
  "Command and Control" = list(c("back.", "land.", "imap."), "T1071", "CWE-1002"),
  "Lateral Movement" = list(c("guess_passwd.", "warezmaster.", "warezclient."), "T1070", "CWE-611"),
  "Exfiltration" = list(c("ftp_write.", "imap.", "spy."), "T1048", "CWE-359"),
  "Persistence" = list(c("rootkit.", "perl.", "loadmodule."), "T1547", "CWE-798"),
  "Defense Evasion" = list(c("ftp_write.", "nmap", "phf."), "T1222", "CWE-200"),
  "Denial of Service" = list(c("smurf.", "neptune.", "teardrop.", "apache2.","pod."), "T1498", "CWE-400"),
  "Normal" = list(c("normal."),"none","none"),
  "NotFound" = list(c("httptunnel.","processtable.","mailbomb.","sqlattack.","worm.","udpstorm.","xterm.","ps.","sendmail.","xlock."),"notfound","notfound")
)

# Función para clasificar la táctica de ATT&CK según las variables del dataset y añadir los IDs correspondientes
clasificar_tactica_attck <- function(registro) {
  for (tactica in names(tacticas_attck)) {
    variables <- tacticas_attck[[tactica]][[1]]
    id_attck <- tacticas_attck[[tactica]][[2]]
    id_cwe <- tacticas_attck[[tactica]][[3]]
    #if (any(registro %in% variables)) {
    if (any(grepl(paste(variables, collapse = "|"), registro))) {
      return(list(Tactica = tactica, ATTCK= id_attck, CWE = id_cwe))
    }
  }
  return(list(Tactica = "Unknown", ATTCK= "Unknown", CWE = "Unknown"))
}

# Aplicar la clasificación a cada registro del dataset y añadir los IDs correspondientes
resultados <- t(sapply(as.character(data_r$Attack), clasificar_tactica_attck))
colnames(resultados) <- c("Tactica", "ID_Tactic", "ID_CWE")

# Unir los resultados al dataset original
data_r <- cbind(data_r, as.data.frame(resultados))
data_r$Tactica <- as.character(data_r$Tactica)
data_r$ID_Tactic <- as.character(data_r$ID_Tactic)
data_r$ID_CWE <- as.character(data_r$ID_CWE)
data_r$Attack <- as.factor(data_r$Attack)
#glimpse(data)
#any(!complete.cases(data))

# Mostrar los valores de Attack que no han podido ser clasificados
unclassified_attacks <- data_r$Attack[data_r$Tactica == "Unknown"]

if (length(unclassified_attacks) > 0) {
  cat("Valores de Attack no clasificados:\n")
  
  # Crear una tabla de valores no clasificados y contar el total de casos por cada valor
  unclassified_table <- table(unclassified_attacks)
  # Filtrar la tabla para incluir solo los valores con más de 1 caso no clasificado
  unclassified_table_filtered <- unclassified_table[unclassified_table > 0]
  
  # Ordenar la tabla por Attack
  unclassified_table <- unclassified_table[order(names(unclassified_table))]
  
  # Mostrar la tabla ordenada y el total de casos por cada valor
  #print(unclassified_table)
} else {
  cat("Todos los valores de Attack han sido clasificados correctamente.")
}

# Gráfico de las partes y relaciones del dataset final
ggplot(data_r, aes(x = Tactica, y = Attack, fill = Tactica)) +
  geom_tile(color = "white") +
  labs(x = "Táctica ATT&CK", y = "Ataque", fill = "Táctica ATT&CK") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) +
  guides(fill = guide_legend(title = "Táctica ATT&CK")) +
  scale_fill_brewer(palette = "Set3")


#### ver si vale la pena incluir estos gráficos
library(DataExplorer)
data_list <- data
plot_str(data_list)
```


#### Fase de testeo de la eficacia de las nuevas variables.

```{r 2_6_tunning_RF_model_group_tests, eval=FALSE, cache=TRUE}
rf_trees_fin <- rf_trees #200
part_fin <- 0.5 
set.seed(123)

data_r$Tactica <- as.factor(data_r$Tactica)

# Añadir columna "Anomaly" al dataset data1
#data_r$Anomaly <- ifelse(data_r$Attack == "normal.", FALSE, TRUE)
#data_r$Anomaly <- as.factor(data_r$Anomaly)
#data_r$Attack <- as.factor(data_r$Attack)

# Prepara la división entre training y testing
inTrain_fin <- createDataPartition(y=data_r$Tactica, p=part_fin, list=FALSE)
training_fin <- data_r[inTrain_fin,]
testing_fin <- data_r[-inTrain_fin,]
prop.table(table(training_fin$Tactica))
prop.table(table(testing_fin$Tactica))

# Entrenar el modelo de Random Forest
control <- rfeControl(functions=rfFuncs, method="cv", number=10)

start_time <- Sys.time()
rf_fin_model <- randomForest(Tactica ~ ., 
                          data = training_fin,
                          mtry = 5,
                          importance = TRUE,
                          rfeControl=control,
                          ntree = rf_trees_fin)
end_time <- Sys.time()
elapsed_time_fin <- round((end_time - start_time), 2)
rf_fin_pred <- predict(rf_fin_model, testing_fin)

cm_fin <- confusionMatrix(rf_fin_pred, testing_fin$Tactica)

#predictors(rf_fin_model)
plot(rf_fin_model)
heatmap(cm_fin$table)

rf_fin_accuracy <- round(cm_fin$overall[1], 4)*100
rf_fin_kappa <- round(cm_fin$overall[2], 4)*100
resultado_final <- data.frame( Accuracy= as.numeric(rf_fin_accuracy),
                               Kappa= as.numeric(rf_fin_kappa),
                               Tiempo= as.numeric(elapsed_time_fin))

print(resultado_final)

# Crear una nueva columna "match" en la tabla valid
valid <- testing_fin %>%
  mutate(Attack = as.character(Tactica),
         pred = as.character(rf_fin_pred),
         match = Attack == pred)

# Calcular el número total de registros por variable Attack
total_per_attack <- table(valid$Tactica)

# Calcular el número de aciertos por variable Attack
aciertos_per_attack <- tapply(valid$match, valid$Tactica, function(x) sum(x))

# Calcular el número de fallos por variable Attack
fallos_per_attack <- total_per_attack - aciertos_per_attack

# Calcular el Accuracy por variable Attack
accuracy_per_attack <- round((aciertos_per_attack / total_per_attack *100), 2)

# Crear la tabla tabla_fin con fallos, aciertos y Accuracy por variable Attack
tabla_fin <- data.frame(Attack = names(total_per_attack),
                        Aciertos = as.integer(aciertos_per_attack),
                        Fallos = as.integer(fallos_per_attack),
                        Accuracy = as.numeric(accuracy_per_attack))

# Ordenar la tabla_fin por Accuracy y Total Aciertos
tabla_fin <- tabla_fin %>%
  arrange(desc(Accuracy), desc(Aciertos))

# Mostrar la tabla tabla_fin actualizada
knitr::kable(tabla_fin, caption = "Resultado por tipo de Attack") %>%
    kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F)

```
# Appendix: Todo el código fuente para este informe

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE, class.source = 'fold-show'}
```





