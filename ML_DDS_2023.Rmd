---
title: "Práctica Final en Data Driven Security"
author: "Grup CC: Toni Jordan Y Joan Dalmau"
date: "Junio de 2023"
output:
  html_document:
    toc: yes
    number_sections: yes
    toc_float: true
    toc_collapsed: true
    toc_depth: 4
    df_print: paged
    theme: spacelab
---

```{r setup, echo=FALSE, results='hide'}
# Opciones de configuración de knitr
options(knitr.kable.NA = '')
knitr::opts_chunk$set(echo = FALSE, fig.align = 'center')

# Cargar paquetes necesarios
library(randomForest)
library(nnet)
library(readr)
library(caret)
library(e1071)  #Naive Bayes
library(dplyr)
library(ggplot2)
library(doParallel) #paralelizacion
library(corrplot)
library(class)
library(data.table)
library(knitr)
library(kableExtra)
library(foreach)  #paralelizacion
library(grid)

#Constantes utilizadas en el programa
rf_trees <- 200    #número máximo de arboles para RandomForest Final
limite <- 50       #número mínimo de muestras para considerar mantener una variable unitaria
```

# Objetivo

El objetivo de esta práctica es realizar un estudio de un subconjunto del Dataset KDD CUP 99 para determinar cuál es el mejor conjunto de variables que podemos usar en un entrenamiento de Machine Learning de clasificación y finalmente conseguir un juego de datos y modelo de entrenamiento que mejore el valor obtenido por el script del enunciado.

Para llevar a cabo este estudio, se dispone de dos archivos de datos con incidencias etiquetadas, una codificación de ejemplo en R, información sobre los estándares Mitre de ATT&CK y unas primeras conclusiones sobre los datos.

## Packages
En esta práctica se utilizarán los siguientes paquetes de R:

```{r load_packages, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
mypackages <- c("randomForest", "nnet", "readr", "caret", "e1071","dplyr","ggplot2", "doParallel","data.table", "kableExtra","corplot","class", "knitr", "tidyr", "grid")

# Crear un data.table con los paquetes
pa<-data.table(mypackages)

# Dividir el data.table en tres partes
cc<-as.integer(length(mypackages)/3)
pa1<-pa[1:cc]
pa2<- pa[(cc+1):(2*cc)]
pa3<- pa[(2*cc+1):length(mypackages)]
```

```{r pack, echo=FALSE, message=FALSE, warning=FALSE}
options(knitr.kable.NA = '')
knitr::kable(list(pa1, pa2, pa3),col.names = NULL, caption = "Required:") %>%
    kable_styling(bootstrap_options = c("striped", "condensed"))
```
## Esquema argumental del documento:

### Validación y pre-porcesado del "Dataset Muestra" respecto al "Dataset Global" entregado  {-}
- Estudio del Dataset Muestra y su contenido  
- Validación de duplicados en el Dataset Muestra  
- Validación de proporciones de la variable "Attack" en el Dataset Muestra  
- Posibilidad de aumentar el número de muestras con el Dataset Global  
- Tratamiento de variables con bajas muestras  

### Selector de variables  {-}
- Criterios de selección y competividad de los precursores con Random Forest  
- Comparativa de diferentes modelos de Machine Learning  
- Optimización del modelo de Machine Learning y conclusiones  

### Mejora de la información y valor añadido  {-}
- Estudios EDA de las variables  
- Información agregada MITRE ATT&CK y CWE  

# Análisis y preprocesamiento de los conjuntos de datos  

En esta sección, se realizará un análisis exploratorio de los conjuntos de datos "Dataset Global" y "Dataset Muestra". Además, se llevará a cabo un preprocesamiento de los datos para asegurarnos de que sean adecuados para su uso en el entrenamiento de modelos de Machine Learning.  

## Carga de los conjuntos de datos  

Comenzamos cargando los conjuntos de datos "Dataset Global" y "Dataset Muestra" en R.  

```{r read_dataset, echo=TRUE, cache=TRUE}
data_full <- read_csv("Book1.csv",
                  col_types = cols(SrcBytes = col_integer(),
                                   DstBytes = col_integer(), Land = col_integer(),
                                   WrongFragment = col_integer(), Urgent = col_number(),
                                   Hot = col_number(), NumFailedLogin = col_integer()))
data <- read.csv("Book2.csv", header=T)
```

### Exploración de los conjuntos de datos  

A continuación, realizaremos un análisis exploratorio de los conjuntos de datos para comprender su estructura y contenido.  

```{r explore_data, echo=FALSE, eval=TRUE, cache=TRUE}
# Visualizar las primeras filas del Dataset Global
head(data_full)

# Visualizar las primeras filas del Dataset Muestra
head(data)
```

El conjunto de datos "Dataset Global" contiene las siguientes columnas: SrcBytes, DstBytes, Land, WrongFragment, Urgent, Hot y NumFailedLogin.... Cada fila representa un incidente.  

El conjunto de datos "Dataset Muestra" contiene las mismas columnas que el conjunto de datos "Dataset Global" y se utiliza como una muestra de incidencias para nuestro estudio.  

### Validación y preprocesamiento del conjunto de datos de muestra  

En esta sección, se realizarán algunas validaciones y preprocesamientos en el conjunto de datos de muestra para asegurarnos de que cumpla con nuestros requisitos.  

#### Estudio del conjunto de datos de muestra y su contenido  {-}

A continuación, se realizará un estudio más detallado del conjunto de datos de muestra y su contenido.  

```{r study_sample_data, eval=FALSE, results='hide'}
# Resumen del conjunto de datos de muestra
summary(data)

# Tipos de datos de las columnas del conjunto de datos de muestra
str(data)
```
```{r echo=TRUE,eval=FALSE} 
dim(data)
```

El conjunto de datos de muestra tiene **`r nrow(data)`** filas y **`r ncol(data)`** columnas. Se distribuyen en los siguientes tipos:

```{r 0_study_data, echo=FALSE, cache=TRUE}
# Contar el número de variables cualitativas, cuantitativas y factor
num_qualitative <- sum(sapply(data, is.character))
num_quantitative <- sum(sapply(data, is.numeric))
num_factor <- sum(sapply(data, is.factor))
  
# Crear una tabla resumen
summary_table <- data.frame(Tipo = c("Cualitativa", "Cuantitativa", "Factor"),
                            Numero = c(num_qualitative, num_quantitative, num_factor))

# Imprimir la tabla resumen usando la función knitr::kable()
knitr::kable(summary_table, caption = "Clasificación por tipos de Variables") %>%
    kable_styling(bootstrap_options = c("striped", "condensed"))
```
Contiene **`r summary_table$Numero[2]`** variable numéricas cuantitativas y **`r summary_table$Numero[1]`** variables cualitativas.

Las columnas cualitativas son: "ProtocolType", "Service", "Flag" y "Attack" que representa la variable objetivo.



```{r 0c_study_data, echo=FALSE, results='hide', cache=TRUE}
# Seleccionar solo las variables cualitativas
qualitative_vars <- select_if(data, is.character)

# Obtener los diferentes valores de las variables cualitativas
distinct_values <- lapply(qualitative_vars, unique)

# Crear una tabla resumen
summary_table2 <- data.frame(Variable = character(), Valores = character(), Categorias = integer(), stringsAsFactors = FALSE)

# Llenar la tabla resumen con los valores diferentes y el número de categorías de cada variable cualitativa
for (i in 1:length(distinct_values)) {
  variable <- names(distinct_values[i])
  values <- paste(distinct_values[[i]], collapse = ", ")
  num_categories <- length(distinct_values[[i]])
  
  summary_table2 <- rbind(summary_table2, data.frame(Variable = variable, Categorias = num_categories, Valores = values))
}

### Ordenar la tabla resumen por nombre de variable
summary_table2 <- summary_table2 %>% arrange(Variable)
```

```{r 0b2_study_data, echo=FALSE, results='hide', fig.align='center', fig.cap='Variables Cualitativas', cache=TRUE}
# Imprimir la tabla resumen
print(summary_table2)

# Crear un gráfico explicativo por cada variable cualitativa
num_variables <- nrow(summary_table2)
num_rows <- 2  # Número de filas en la matriz de gráficos
num_cols <- ceiling(num_variables / num_rows)  # Número de columnas en la matriz de gráficos

# Establecer la disposición de los gráficos
layout(matrix(1:num_variables, nrow = num_rows, ncol = num_cols))

for (i in 1:num_variables) {
  variable <- summary_table2$Variable[i]
  plot_data <- table(data[[variable]])
  
  plot <- barplot(plot_data, main = paste("Número de Muestras por Valor Cualitativo -", variable),
                  xlab = "Valor Cualitativo", ylab = "Número de Muestras",
                  col = "skyblue", border = "white")
  
  # Imprimir el gráfico
  print(plot)
}

# Restaurar la configuración del dispositivo gráfico
layout(1)
```

### Validación de duplicados en el conjunto de datos de muestra

Vamos a validar si el conjunto de datos de muestra contiene filas duplicadas y, en caso afirmativo, eliminaremos las duplicadas.

```{r 1b_study_data, echo=FALSE, results='hide', cache=TRUE}
# Calcular el número de muestras duplicadas o iguales
duplicates <- data %>%
  group_by_all() %>%
  filter(n() > 1) %>%
  summarise(Num_Duplicates = n()) %>%
  arrange(desc(Num_Duplicates))
print(summary_table)
```

```{r 0b3_study_data, echo=FALSE, cache=TRUE}
# Imprimir la tabla ordenada
print(duplicates)

# Eliminar las muestras duplicadas y conservar solo una muestra de ellas
kdd_data_unique <- distinct(data, .keep_all = TRUE)
# Calcular el número de muestras duplicadas eliminadas
duplicates <- nrow(data) - nrow(kdd_data_unique)
# Imprimir el número de muestras duplicadas eliminadas
cat("Número de muestras duplicadas eliminadas:", duplicates, "\n")
rm(kdd_data_unique) #eliminamos dataset temporal
```

### Con el siguiente estudio se analiza el Dataset Muestra y el Dataset Global 

```{r 2_study_data, echo=FALSE, cache=TRUE}
#Valor extremoa de la diferencia de porcetage permitido XX% y cantidad mínima de muestras
difer_n <- 3
cant_min <- 1000

### nueva version
# Filtrar los valores donde la variable Attack no es igual a "normal"
filtered_data_full <- data_full[data_full$Attack != "normal.", ]
filtered_data <- data[data$Attack != "normal.", ]

# Eliminar las muestras duplicadas y conservar solo una muestra de ellas
kdd_data_full_unique <- distinct(filtered_data_full, .keep_all = TRUE)
# Calcular el número de muestras duplicadas eliminadas
duplicates <- nrow(filtered_data_full) - nrow(kdd_data_full_unique)
# Imprimir el número de muestras duplicadas eliminadas
cat("Número de muestras duplicadas eliminadas:", duplicates, "\n")
filtered_data_full <- kdd_data_full_unique

# Calcular la frecuencia y porcentaje de casos por valor de Attack
attack_counts_full <- filtered_data_full %>% 
  count(Attack) %>%
  mutate(Percentage_Full = round(n/sum(n) * 100, 2)) %>%
  arrange(desc(Percentage_Full))

attack_counts <- filtered_data %>% 
  count(Attack) %>%
  mutate(Percentage = round(n/sum(n) * 100, 2)) %>%
  arrange(desc(Percentage))

# Crear una tabla combinada con los totales y porcentajes
attack_table <- merge(attack_counts_full, attack_counts, by = "Attack", suffixes = c("_Full", "_Ini"))
attack_table <- attack_table[order(attack_table$n_Full, decreasing = TRUE),]

# Calcular la diferencia entre Porcentaje_Full y Porcentaje_Ini
attack_table$Diferencia <- abs(attack_table$Percentage_Full - attack_table$Percentage)
attack_table$Disponibles <- attack_table$n_Full-attack_table$n_Ini

# Filtrar los casos con diferencia mayor al XX%
filtered_attack_table <- attack_table[attack_table$Diferencia > difer_n, ]
filtered_attack_table_n <- attack_table[attack_table$n_Ini < cant_min, ]

# Imprimir la tabla de casos con diferencia mayor al XX%
print(attack_table) 
print(filtered_attack_table)
print(filtered_attack_table_n)
rm(kdd_data_full_unique) #eliminamos dataset temporal
```

### Con el siguiente estudio se concluye que el Dataset Muestra es ya el Dataset Global filtrado y no es posible poblar el Dataset de trabajo

```{r 3_study_data, echo=FALSE, fig.align='center', fig.cap='Comparativa Data_Full<>Data', cache=TRUE}
# Crear un gráfico de barras comparativo
comparison_plot <- ggplot(filtered_attack_table, aes(x = Attack, y = Diferencia)) +
  geom_bar(stat = "identity", fill = "blue", alpha = 0.5) +
  labs(x = "Attack", y = "Diferencia") +
  ggtitle("Diferencia en Porcentaje_Full y Porcentaje_Ini") +
  theme_minimal()

# Imprimir el gráfico
print(comparison_plot)
rm(data_full)
```

## Tratamiento de las muestras residuales
```{r  4_study_data, echo=FALSE, fig.align='center', fig.cap='Agrupando variables residuales', out.width='50%', fig.show='hold', cache=TRUE}
#data <- read.csv("Book2.csv",header=T)
#limite <- 50       #número mínimo de muestras para considerarla independientemente

# Filtrar los casos que no tienen el valor "normal."
data_filtered <- data %>% filter(Attack != "normal.")

# Contar la frecuencia de los valores en la columna "Attack"
frecuencia_attack <- sort(table(data_filtered$Attack), decreasing = TRUE)

# Calcular el porcentaje de casos por valor de Attack
attack_counts <- data_filtered %>% 
  count(Attack) %>%
  mutate(Percentage = round(n/sum(n) * 100, 2)) %>%
  arrange(desc(Percentage))

# Crea una tabla ordenada con los totales
attack_table <- data.frame(
  Attack = names(frecuencia_attack), 
  Total = as.numeric(frecuencia_attack), 
  Porcentaje = as.numeric(attack_counts$Percentage)
)
attack_table <- attack_table[order(attack_table$Total, decreasing = TRUE), ]

# Imprime la tabla ordenada
print(attack_table)

# Crear un gráfico de barras del porcentaje de casos por valor de Attack
ggplot(attack_counts, aes(x = reorder(Attack, -Percentage), y = Percentage)) +
  geom_bar(stat = "identity", fill = "blue") +
  labs(title = "Porcentaje de casos por valor de Attack",
       x = "Attack",
       y = "Porcentaje de casos") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Reemplazar valores inferiores a XX por "other" en el dataset data
data$Attack <- ifelse(data$Attack %in% attack_table$Attack[attack_table$Total < limite], "other", data$Attack)

# Filtrar los casos que no tienen el valor "normal."
data_filtered <- data %>% filter(Attack != "normal.")

# Contar la frecuencia de los valores en la columna "Attack"
frecuencia_attack <- sort(table(data_filtered$Attack), decreasing = TRUE)

# Calcular el porcentaje de casos por valor de Attack
attack_counts <- data_filtered %>% 
  count(Attack) %>%
  mutate(Percentage = round(n/sum(n) * 100, 2)) %>%
  arrange(desc(Percentage))

# Crea una tabla ordenada con los totales
attack_table_final <- data.frame(
  Attack = names(frecuencia_attack), 
  Total = as.numeric(frecuencia_attack), 
  Porcentaje = as.numeric(attack_counts$Percentage)
)
attack_table_final <- attack_table_final[order(attack_table_final$Total, decreasing = TRUE), ]
print(attack_table_final)

# Crear un gráfico de barras del porcentaje de casos por valor de Attack
ggplot(attack_counts, aes(x = reorder(Attack, -Percentage), y = Percentage)) +
  geom_bar(stat = "identity", fill = "blue") +
  labs(title = "Porcentaje de casos por valor de Attack",
       x = "Attack",
       y = "Porcentaje de casos") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r 4b_study_data, echo=FALSE}

```

Aunque la creación de un buen modelo debe entenderse como un proceso iterativo, en el que se van ajustando y probando distintos modelos, existen ciertas pistas que pueden ayudar a realizar una selección inicial adecuada.

Si dos variables numéricas están muy correlacionadas, añaden información redundante al modelo, por lo tanto, no conviene incorporar ambas. Si esto ocurre, se puede: excluir aquella que, acorde al criterio del analista, no está realmente asociada con la variable respuesta; o combinarlas para recoger toda su información en una única nueva variable, por ejemplo, con un PCA.

Si una variable tiene varianza igual o próxima a cero (su valor es el mismo o casi el mismo para todas las observaciones) añade al modelo más ruido que información, por lo que suele ser conveniente excluirla.

Si alguno de los niveles de una variable cualitativa tiene muy pocas observaciones en comparación a los otros niveles, puede ocurrir que, durante la validación cruzada o bootstrapping, algunas particiones no contengan ninguna observación de dicha clase (varianza cero), lo que puede dar lugar a errores. En estos casos, suele ser conveniente eliminar las observaciones del grupo minoritario (si es una variable multiclase), eliminar la variable (si solo tiene dos niveles) o asegurar que, en la creación de las particiones, se garantice que todos los grupos estén representados en cada una de ellas.

## Selección de Predictores

Sección de carga de los diferentes modelos de subset por variables
```{r 2_feature_selection, echo=FALSE, cache=TRUE}
# Enunciado de la práctica
data1_original <- data[,c("SrcBytes", "DstBytes", "Land", "WrongFragment", "Urgent", "SameSrvRate", "LoggedIn",  "DstHostSameSrvRate", "DstHostSrvCount","Flag","Attack" )]

# pdf de soporte
data1_pdf <- data[,c("SrcBytes", "DstBytes", "DstHostSameSrvRate", "Count", "DstHostDiffSrvRate","Attack" )]

# Criterio teórico de los expertos en Networking
data1_teorico <- data[,c("SrcBytes", "DstBytes", "Land", "WrongFragment", "Urgent", "Hot","NumFailedLogin","Attack" )]
data1_original$Attack <- as.factor(data1_original$Attack)
data1_pdf$Attack <- as.factor(data1_pdf$Attack)
data1_teorico$Attack <- as.factor(data1_teorico$Attack)
```

### modulo de selección de las variables finales por criterios puramente estadísticos
```{r 2_2_feature_selection, echo=FALSE}
# Criterio de la Varianza, para validación manual
#data1 <- data[,c("SrcBytes", "DstBytes", "Count", "DstHostSameSrvRate", "DstHostDiffSrvRate", "DstHostSrvDiffHostRate", "LoggedIn","SrvCount", "SerrorRate", "SrvSerrorRate", "RerrorRate", "SrvRerrorRate", "DiffSrvRate","SrvDiffHostRate", "DstHostSrvCount", "DstHostSameSrcPortRate", "DstHostSerrorRate", "DstHostSrvSerrorRate", "DstHostRerrorRate", "DstHostSrvRerrorRate","Attack" )]

# me quedo solo con las variables numéricas en nuevo data1
numeric_cols <- sapply(data, is.numeric)
data1 <- data[, numeric_cols == TRUE] 
# elimino variables con Varianza zero y nzv, #eliminará la variable NumOutboundCmds
variance <- nearZeroVar(data1, saveMetrics = T)
data1 <- data1[, !(variance$zeroVar | variance$nzv)]

# Se añade la variable numerica SrcBytes ya que detectado mejora la predicción
data1$SrcBytes <- data$SrcBytes

# Buscamos variables correladas
correlation <- cor(data1)
corrplot(correlation, method="circle", na.label= '.')
highlyCorrelated <- findCorrelation(correlation, verbose=F, names=T)
#print(highlyCorrelated)

#columna con alta correlación entre ellas, se pueden eliminar
columns_to_remove <- c("DstHostSameSrvRate", "DstHostSrvRerrorRate", "DstHostRerrorRate", "RerrorRate", "DstHostSrvSerrorRate", "DstHostSerrorRate", "SrvSerrorRate")
data1 <- data1[, setdiff(names(data1), columns_to_remove)]

# Añadir la variable "Attack" al dataset filtrado
data1$Attack <- as.factor(data$Attack)
```

```{r 2_1_feature_selection, echo=FALSE, cache=TRUE}
parte <- 0.1  #mínima toma de muestras para acelerar el cálculo

set.seed(123)
inTrain <- createDataPartition(y=data1$Attack, p=parte, list=FALSE)
inTrain_original <- createDataPartition(y=data1_original$Attack, p=parte, list=FALSE)
inTrain_pdf <- createDataPartition(y=data1_pdf$Attack, p=parte, list=FALSE)
inTrain_teorico <- createDataPartition(y=data1_teorico$Attack, p=parte, list=FALSE)

training <- data1[inTrain,]
testing <- data1[-inTrain,]
dim(training)

training_original <- data1_original[inTrain_original,]
testing_original <- data1_original[-inTrain_original,]
dim(training_original)

training_pdf <- data1_pdf[inTrain_pdf,]
testing_pdf <- data1_pdf[-inTrain_pdf,]
dim(training_pdf)

training_teorico <- data1_teorico[inTrain_teorico,]
testing_teorico <- data1_teorico[-inTrain_teorico,]
dim(training_teorico)
```

```{r 2_1_feature_selection_train_random_forest, echo=FALSE, cache=TRUE}
#rf_trees <- 200
output.forest <- randomForest(Attack ~ ., data = training, ntree = rf_trees, na.action=na.fail)
output.forest_ori <- randomForest(Attack ~ ., data = training_original, ntree = rf_trees, na.action=na.fail)
output.forest_pdf <- randomForest(Attack ~ ., data = training_pdf, ntree = rf_trees, na.action=na.fail)
output.forest_teo <- randomForest(Attack ~ ., data = training_teorico, ntree = rf_trees, na.action=na.fail)
```

```{r 2_1_feature_selection_predict, echo=FALSE, cache=TRUE}
pred <- predict(output.forest,testing)
rf_accuracy <- sum(pred == testing$Attack) / length(pred)

pred_ori <- predict(output.forest_ori,testing_original)
pred_pdf <- predict(output.forest_pdf,testing_pdf)
pred_teo <- predict(output.forest_teo,testing_teorico)

ok <- round(sum(pred == testing$Attack) / length(pred)*100, 2)
ok_ori <- round(sum(pred_ori == testing_original$Attack) / length(pred_ori)*100, 2)
ok_pdf <- round(sum(pred_pdf == testing_pdf$Attack) / length(pred_pdf)*100, 2)
ok_teo <- round(sum(pred_teo == testing_teorico$Attack) / length(pred_teo)*100, 2)

tabla_resultados <- data.frame(Variable = c("Propuesto", "Enunciado", "Ejemplo_PDF", "Teórico"),
                              Valor = c(ok, ok_ori, ok_pdf, ok_teo))
print(tabla_resultados)

cm_rf <- confusionMatrix(pred, testing$Attack)
cm_ori <- confusionMatrix(pred_ori, testing_original$Attack)
cm_pdf <- confusionMatrix(pred_pdf, testing_pdf$Attack)
cm_teo <- confusionMatrix(pred_teo, testing_teorico$Attack)
heatmap(cm_rf$table)
heatmap(cm_ori$table)
heatmap(cm_pdf$table)
heatmap(cm_teo$table)

#elimina dataset temporales
rm(data1_teorico, data1_pdf, data1_original)
rm(training_teorico, training_pdf, training_original)
rm(testing_teorico, testing_pdf, testing_original)
rm(cm_teo, cm_pdf, cm_ori)
rm(output.forest_teo, output.forest_pdf, output.forest_ori)
rm(inTrain_teorico, inTrain_pdf, inTrain_original)
```

 **Conclusión: nos quedamos con la propuesta de variables púramente estadística**

```{r 2_3_other_model_tests, echo=FALSE, results='hide', fig.align='center', out.width='50%', fig.show='hold', cache=TRUE}
# Función para calcular precisión y tiempo de ejecución
calculate_accuracy_time <- function(model, training, testing) {
  end_time <- Sys.time()
  elapsed_time <- round((end_time - start_time), 2)
  pred <- predict(model, testing)
  cm_model <- confusionMatrix(pred, testing$Attack)
  cm_accuracy <- round(cm_model$overall[1], 4)*100
  cm_kappa <- round(cm_model$overall[2], 4)*100
  heatmap(cm_model$table)
  return(list(accuracy = cm_accuracy, cm_kappa = cm_kappa, elapsed_time = elapsed_time))
}

# Me quedo con las variables numéricas
num_vars <- sapply(training, is.numeric)
training_num <- training[, num_vars]

control <- trainControl(method = "cv", number = 2)
metric <- "Accuracy"
set.seed(123)

# Random Forest
start_time <- Sys.time()
rf_model <- randomForest(Attack ~ ., data = training, ntree = 100)
rf_results <- calculate_accuracy_time(rf_model, training, testing)

# Red Neuronal
#start_time <- Sys.time()
#nn_model <- nnet(Attack ~ ., data = training, size = 5, maxit = 100)
#nn_results <- calculate_accuracy_time(nn_model, training, testing)

# Support Vector Machine
start_time <- Sys.time()
svm_model <- svm(Attack ~ ., data = training)
svm_results <- calculate_accuracy_time(svm_model, training, testing)

# CART (Classification and Regression Trees)
start_time <- Sys.time()
fit.cart <- train(Attack ~ ., data = training, method = "rpart", metric = metric, trControl = control)
cart_results <- calculate_accuracy_time(fit.cart, training, testing)

# KNN (K-Nearest Neighbors)
start_time <- Sys.time()
knn_model <- knn(train = training_num, test = testing[, 1:13], cl = training$Attack, k = 5)
end_time <- Sys.time()
elapsed_time_knn <- round((end_time - start_time), 2)
knn_accuracy <- round(sum(knn_model == testing$Attack) / length(knn_model) * 100, 2)
knn_results <- list(accuracy = knn_accuracy, elapsed_time = elapsed_time_knn)
cm_model <- confusionMatrix(knn_model, testing$Attack)
knn_results <- list(accuracy = round(cm_model$overall[1], 4)*100, 
                     cm_kappa= round(cm_model$overall[2], 4)*100, elapsed_time = elapsed_time_knn )
heatmap(cm_model$table)

# Naive Bayes
start_time <- Sys.time()
nb_model <- naiveBayes(Attack ~ ., data = training)
nb_results <- calculate_accuracy_time(nb_model, training, testing)

# Resultados
results <- data.frame(Modelo = c("Random Forest", "Support Vector Machine", "CART", "K-NearestN", "Naive Bayes"),
                      Accuracy = c(rf_results$accuracy, svm_results$accuracy,
                                    cart_results$accuracy, knn_results$accuracy, nb_results$accuracy),
                      Kappa = c(rf_results$cm_kappa, svm_results$cm_kappa,
                                    cart_results$cm_kappa, knn_results$cm_kappa, nb_results$cm_kappa),
                      Tiempo = c(rf_results$elapsed_time, svm_results$elapsed_time, 
                                 cart_results$elapsed_time, knn_results$elapsed_time, nb_results$elapsed_time))

print(results)
knitr::kable(results, caption = "Resultados por métodos de Clasificación") %>%
    kable_styling(bootstrap_options = c("striped", "condensed"))
```

### Entrenamiento con Random Forest Final
```{r 2_4_tunning_RF_model_tests, echo=FALSE, cache=TRUE}
rf_trees_fin <- rf_trees #200
part_fin <- 0.5 
set.seed(123)

# Añadir columna "Anomaly" al dataset data1
data1$Anomaly <- ifelse(data1$Attack == "normal.", FALSE, TRUE)
data1$Anomaly <- as.factor(data1$Anomaly)

data1$Attack <- as.factor(data1$Attack)

# Prepara la división entre training y testing
inTrain_fin <- createDataPartition(y=data1$Attack, p=part_fin, list=FALSE)
training_fin <- data1[inTrain_fin,]
testing_fin <- data1[-inTrain_fin,]
prop.table(table(training_fin$Attack))
prop.table(table(testing_fin$Attack))

# Entrenar el modelo de Random Forest
control <- rfeControl(functions=rfFuncs, method="cv", number=10)

start_time <- Sys.time()
rf_fin_model <- randomForest(Attack ~ ., 
                          data = training_fin,
                          mtry = 5,
                          importance = TRUE,
                          rfeControl=control,
                          ntree = rf_trees_fin)
end_time <- Sys.time()
elapsed_time_fin <- round((end_time - start_time), 2)
rf_fin_pred <- predict(rf_fin_model, testing_fin)

cm_fin <- confusionMatrix(rf_fin_pred, testing_fin$Attack)

predictors(rf_fin_model)
plot(rf_fin_model)
heatmap(cm_fin$table)

rf_fin_accuracy <- round(cm_fin$overall[1], 4)*100
rf_fin_kappa <- round(cm_fin$overall[2], 4)*100
resultado_final <- data.frame( Accuracy= as.numeric(rf_fin_accuracy),
                               Kappa= as.numeric(rf_fin_kappa),
                               Tiempo= as.numeric(elapsed_time_fin))

print(resultado_final)

# Crear una nueva columna "match" en la tabla valid
valid <- testing_fin %>%
  mutate(Attack = as.character(Attack),
         pred = as.character(rf_fin_pred),
         match = Attack == pred)

# Calcular el número total de registros por variable Attack
total_per_attack <- table(valid$Attack)

# Calcular el número de aciertos por variable Attack
aciertos_per_attack <- tapply(valid$match, valid$Attack, function(x) sum(x))

# Calcular el número de fallos por variable Attack
fallos_per_attack <- total_per_attack - aciertos_per_attack

# Calcular el Accuracy por variable Attack
accuracy_per_attack <- round((aciertos_per_attack / total_per_attack *100), 2)

# Crear la tabla tabla_fin con fallos, aciertos y Accuracy por variable Attack
tabla_fin <- data.frame(Attack = names(total_per_attack),
                        Aciertos = as.integer(aciertos_per_attack),
                        Fallos = as.integer(fallos_per_attack),
                        Accuracy = as.numeric(accuracy_per_attack))

# Ordenar la tabla_fin por Accuracy y Total Aciertos
tabla_fin <- tabla_fin %>%
  arrange(desc(Accuracy), desc(Aciertos))

# Mostrar la tabla tabla_fin actualizada
print(tabla_fin)
```

# EDA: Esta sección es para completar el estudio de los datos y sus relaciones

Categorias principales de intrusiones:

DOS: denial-of-service, e.g. syn flood;
R2L: unauthorized access from a remote machine, e.g. guessing password;
U2R: unauthorized access to local superuser (root) privileges, e.g., various ``buffer overflow'' attacks;
probing: surveillance and other probing, e.g., port scanning.

# Observación: DstHostSameSrcPortRate tiene un ligero efecto en el tipo de intrusión, para "DstHostSameSrcPortRate" mayor a igual a 1 puede ser "probe" de "r2l"
```{r 3_1_eda1, echo=TRUE, cache=TRUE}
qplot(DstHostSameSrvRate,DstHostSrvCount,colour=Attack,data=data)
```
Plot mean attack duration and median attack duration.
```{r, cache=TRUE}
ggplot(data=data, aes(x=data$Attack, y=data$Duration, fill = data$Attack)) + 
  geom_bar(stat = "summary", fun.y = "mean")+scale_x_discrete(name = "Attack")+
  scale_y_continuous("Duration")+labs(title="Mean attack duration", fill=("Attack\n") )

#median attack duraction
ggplot(data=data, aes(x=data$Attack, y=data$Duration, fill = data$Attack)) + 
  geom_bar(stat = "summary", fun.y = "median")+scale_x_discrete(name = "Attack")+
  scale_y_continuous("Duration")+labs(title="Median attack duration", fill=("Attack\n") )
```
The graphs show that the average durations reflect the type of attack. 
In fact, a DoS attack has an average duration of zero since its goal is to make a physical device in the network unusable. In this way, the service does down and the average duration is almost zero.
Note that, a Probing attack, which should get as much information as possible about network security, has a large average duration.
While, only the User to Root attack (u2r) has a very high median. In fact, the durations of this attack are comparable to each other, while this does not happen for other types of attacks that have very variable duration between them.

Plot average duration of attacks based on the type of protocol.
```{r, cache=TRUE}
ggplot(data=data, aes(x=data$Attack, y=data$Duration, fill = data$ProtocolType)) + 
  geom_bar(stat = "summary", fun.y = "mean")+scale_x_discrete(name = "Attack")+
  scale_y_continuous("Duration")+ scale_fill_discrete(name = "Protocol type\n")+
  labs(title="Average duration of attacks based on the type of protocol" )
```

Como se puede observar en el gráfico, los tipos de ataques reflejan la duración promedio basada en el tipo de protocolo. De hecho, muchos ataques utilizan el protocolo TCP que se utiliza ampliamente para implementar diferentes servicios. El uso extensivo del protocolo UDP en casos normales es extraño, pero depende del tipo de solicitudes de servicio del usuario.

Observaciones individuales usando 'Duration', 'Attack' y 'protocol type'.
```{r, cache=TRUE}
p1 <- ggplot(data,aes(y = data$Duration, x = data$Attack)) +
  geom_point()
p1 +  geom_point(aes(color=data$ProtocolType))+
  labs(title="Duraction, attack and protocol type" , color ="Protocol type")+
  scale_x_discrete(name = "Attack")+
  scale_y_discrete("Duration")
```

# Observatión: "Flag" es un buen predictor. Flag= "REG" y "S0" es tipo "DoS"
```{r eda2, echo=TRUE, cache=TRUE}
qplot(Service,Flag,colour=Attack,data=data)
```

# Observación: Para duración mayor hay de 30000 se puede ver un 'probe', la duración misma es un fuerte predictor
```{r eda3, echo=TRUE, cache=TRUE}
qplot(Duration,SrcBytes,colour=Attack,data=data)
```

# Observación: Para duración mayor 30000 puede ser un 'probe'
# Observación: ProtocolType "tcp" tiene "DOS" tipo de intrusion. Es un fuerte predictor del tipo "DoS".
```{r eda4, echo=TRUE, cache=TRUE}
qplot(Service,ProtocolType,colour=Attack,data=data)
```

# Observación: No hay una clara identificación
```{r eda5, echo=TRUE, cache=TRUE}
qplot(Flag,Land,colour=Attack,data=data)
```

# Observación: Para SerrorRate y SrvSerrorRate=0 or 1 es tipo "Dos" y SerrorRate entre 0.25 a 0.5 es un "probe""
```{r eda6, echo=TRUE, cache=TRUE}
qplot(SerrorRate,SrvSerrorRate,colour=Attack,data=data)
```

# Observación: para duración mayor de 30000 puede ser un 'probe'
```{r eda7, echo=TRUE, cache=TRUE}
qplot(Duration,SrcBytes,colour=Attack,data=data)
```

# Resultado: claramente Flag is un potente predictor para incrusiones de tipo "DoS"
```{r eda8, echo=TRUE, cache=TRUE}
A=table(data$Flag,data$Attack)
round(prop.table(A)*100,1)
```

# Enriquecemos el Dataset con: las tácticas de ATT&CK y las variables relacionadas con su ID según estándard MITRE y el ID de CWE
```{r 3_2_add_standard, echo=FALSE, cache=TRUE}

#### 1. carga limpio el Dataset
data <- read.csv("Book2.csv",header=T)
data_r <- data

#### 2. me quedo solo con las variables numéricas en nuevo data_r
numeric_cols <- sapply(data_r, is.numeric)
data_r <- data_r[, numeric_cols == TRUE] 
# elimino variables con Varianza zero y nzv, #eliminará la variable NumOutboundCmds
variance <- nearZeroVar(data_r, saveMetrics = T)
data_r <- data_r[, !(variance$zeroVar | variance$nzv)]
# Se añade la variable numerica SrcBytes ya que detectado mejora la predicción
data_r$SrcBytes <- data$SrcBytes

#### 3. columna con alta correlación entre ellas, se pueden eliminar
columns_to_remove <- c("DstHostSameSrvRate", "DstHostSrvRerrorRate", "DstHostRerrorRate", "RerrorRate", "DstHostSrvSerrorRate", "DstHostSerrorRate", "SrvSerrorRate")
data_r <- data_r[, setdiff(names(data_r), columns_to_remove)]

#### 4. Se añade la variable numerica SrcBytes ya que detectado mejora la predicción
data_r$SrcBytes <- data$SrcBytes
data_r$Attack <- as.factor(data$Attack)

#### 5. Definir las tácticas de ATT&CK y las variables relacionadas con su ID según estándard MITRE y CWE
tacticas_attck <- list(
  "Reconnaissance" = list(c("nmap.", "satan.", "mscan.", "snmpgetattack.", "named.", "ipsweep.", "xsnoop", "xclock.", "saint.","snmpguess.","portsweep"), "T0497", "CWE-200"),
  "Delivery" = list(c("smurf.", "neptune.", "teardrop."), "T1496", "CWE-693"),
  "Exploitation" = list(c("buffer_overflow.", "rootkit.", "loadmodule."), "T1203", "CWE-119"),
  "Privilege Escalation" = list(c("ftp_write.", "multihop.", "phf."), "T1068", "CWE-732"),
  "Command and Control" = list(c("back.", "land.", "imap."), "T1071", "CWE-1002"),
  "Lateral Movement" = list(c("guess_passwd.", "warezmaster.", "warezclient."), "T1070", "CWE-611"),
  "Exfiltration" = list(c("ftp_write.", "imap.", "spy."), "T1048", "CWE-359"),
  "Persistence" = list(c("rootkit.", "perl.", "loadmodule."), "T1547", "CWE-798"),
  "Defense Evasion" = list(c("ftp_write.", "nmap", "phf."), "T1222", "CWE-200"),
  "Denial of Service" = list(c("smurf.", "neptune.", "teardrop.", "apache2.","pod."), "T1498", "CWE-400"),
  "Normal" = list(c("normal."),"none","none"),
  "NotFound" = list(c("httptunnel.","processtable.","mailbomb.","sqlattack.","worm.","udpstorm.","xterm.","ps.","sendmail.","xlock."),"notfound","notfound")
)

# Función para clasificar la táctica de ATT&CK según las variables del dataset y añadir los IDs correspondientes
clasificar_tactica_attck <- function(registro) {
  for (tactica in names(tacticas_attck)) {
    variables <- tacticas_attck[[tactica]][[1]]
    id_attck <- tacticas_attck[[tactica]][[2]]
    id_cwe <- tacticas_attck[[tactica]][[3]]
    #if (any(registro %in% variables)) {
    if (any(grepl(paste(variables, collapse = "|"), registro))) {
      return(list(Tactica = tactica, ATTCK= id_attck, CWE = id_cwe))
    }
  }
  return(list(Tactica = "Unknown", ATTCK= "Unknown", CWE = "Unknown"))
}

# Aplicar la clasificación a cada registro del dataset y añadir los IDs correspondientes
resultados <- t(sapply(as.character(data_r$Attack), clasificar_tactica_attck))
colnames(resultados) <- c("Tactica", "ID_Tactic", "ID_CWE")

# Unir los resultados al dataset original
data_r <- cbind(data_r, as.data.frame(resultados))
data_r$Tactica <- as.character(data_r$Tactica)
data_r$ID_Tactic <- as.character(data_r$ID_Tactic)
data_r$ID_CWE <- as.character(data_r$ID_CWE)
data_r$Attack <- as.factor(data_r$Attack)
#glimpse(data)
#any(!complete.cases(data))

# Mostrar los valores de Attack que no han podido ser clasificados
unclassified_attacks <- data_r$Attack[data_r$Tactica == "Unknown"]

if (length(unclassified_attacks) > 0) {
  cat("Valores de Attack no clasificados:\n")
  
  # Crear una tabla de valores no clasificados y contar el total de casos por cada valor
  unclassified_table <- table(unclassified_attacks)
  # Filtrar la tabla para incluir solo los valores con más de 1 caso no clasificado
  unclassified_table_filtered <- unclassified_table[unclassified_table > 0]
  
  # Ordenar la tabla por Attack
  unclassified_table <- unclassified_table[order(names(unclassified_table))]
  
  # Mostrar la tabla ordenada y el total de casos por cada valor
  print(unclassified_table)
} else {
  cat("Todos los valores de Attack han sido clasificados correctamente.")
}
```

# Fase de testeo de la eficacia de las nuevas variables.

```{r 2_6_tunning_RF_model_group_tests, echo=FALSE, cache=TRUE}
rf_trees_fin <- rf_trees #200
part_fin <- 0.5 
set.seed(123)

data_r$Tactica <- as.factor(data_r$Tactica)

# Añadir columna "Anomaly" al dataset data1
#data_r$Anomaly <- ifelse(data_r$Attack == "normal.", FALSE, TRUE)
#data_r$Anomaly <- as.factor(data_r$Anomaly)
#data_r$Attack <- as.factor(data_r$Attack)

# Prepara la división entre training y testing
inTrain_fin <- createDataPartition(y=data_r$Tactica, p=part_fin, list=FALSE)
training_fin <- data_r[inTrain_fin,]
testing_fin <- data_r[-inTrain_fin,]
prop.table(table(training_fin$Tactica))
prop.table(table(testing_fin$Tactica))

# Entrenar el modelo de Random Forest
control <- rfeControl(functions=rfFuncs, method="cv", number=10)

start_time <- Sys.time()
rf_fin_model <- randomForest(Tactica ~ ., 
                          data = training_fin,
                          mtry = 5,
                          importance = TRUE,
                          rfeControl=control,
                          ntree = rf_trees_fin)
end_time <- Sys.time()
elapsed_time_fin <- round((end_time - start_time), 2)
rf_fin_pred <- predict(rf_fin_model, testing_fin)

cm_fin <- confusionMatrix(rf_fin_pred, testing_fin$Tactica)

predictors(rf_fin_model)
plot(rf_fin_model)
heatmap(cm_fin$table)

rf_fin_accuracy <- round(cm_fin$overall[1], 4)*100
rf_fin_kappa <- round(cm_fin$overall[2], 4)*100
resultado_final <- data.frame( Accuracy= as.numeric(rf_fin_accuracy),
                               Kappa= as.numeric(rf_fin_kappa),
                               Tiempo= as.numeric(elapsed_time_fin))

print(resultado_final)

# Crear una nueva columna "match" en la tabla valid
valid <- testing_fin %>%
  mutate(Attack = as.character(Tactica),
         pred = as.character(rf_fin_pred),
         match = Attack == pred)

# Calcular el número total de registros por variable Attack
total_per_attack <- table(valid$Tactica)

# Calcular el número de aciertos por variable Attack
aciertos_per_attack <- tapply(valid$match, valid$Tactica, function(x) sum(x))

# Calcular el número de fallos por variable Attack
fallos_per_attack <- total_per_attack - aciertos_per_attack

# Calcular el Accuracy por variable Attack
accuracy_per_attack <- round((aciertos_per_attack / total_per_attack *100), 2)

# Crear la tabla tabla_fin con fallos, aciertos y Accuracy por variable Attack
tabla_fin <- data.frame(Attack = names(total_per_attack),
                        Aciertos = as.integer(aciertos_per_attack),
                        Fallos = as.integer(fallos_per_attack),
                        Accuracy = as.numeric(accuracy_per_attack))

# Ordenar la tabla_fin por Accuracy y Total Aciertos
tabla_fin <- tabla_fin %>%
  arrange(desc(Accuracy), desc(Aciertos))

# Mostrar la tabla tabla_fin actualizada
print(tabla_fin)
```






